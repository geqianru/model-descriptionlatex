\documentclass[preprint,12pt]{elsarticle}
\usepackage{setspace}
\onehalfspacing
\usepackage{fullpage}
\usepackage{booktabs,multirow} % for adding brackets in tables
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[english]{babel}
\usepackage{longtable}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{latexsym}
\usepackage{morefloats}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{rotating}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage[nodots]{numcompress}
\usepackage{booktabs}
\usepackage{epstopdf}
\usepackage{booktabs,caption,fixltx2e}
\usepackage[flushleft]{threeparttable}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareGraphicsExtensions{.pdf,.eps}
%\DeclarePairedDelimiter
\usepackage[toc,page]{appendix}
\usepackage{natbib}
\begin{document}
\nocite{*}

\begin{frontmatter}
\title{Reliability Optimization for series systems under uncertain component reliability in the design phase}
\author[label1]{Qianru Ge}
\author[label1]{Hao Peng}
\author[label1]{Geert-Jan van Houtum}
\author[label1]{Ivo Adan}
\address[label1]{Department of Industrial Engineering and Innovation Sciences, Eindhoven University of Technology, Eindhoven, The Netherlands}

\begin{abstract}
%We consider an OEM who sells a series system for a customer under a Performance-Based Logistic (PBL) contract. During the design phase of the system, the OEM have to select an optimal design for each critical component in the system from all the possible alternatives with uncertain component reliability. The uncertainty  in component reliabilities can lead to large deviations of the realized system availability from the expected system availability. Upon a failure of a critical component in the system, the failed part will be replaced by a as-good-as new component. According to the PBL contract, when the total system down time exceeds a predetermined level, the OEM should pay a penalty cost to the customer with respect to the actual total downtime and a penalty rate. In this case, we formulate the Life Cycle Costs (LCC) of this multi-stage system which are affected by the uncertain component reliability. The LCC consist of design costs, repair costs and downtime costs.
\end{abstract}

\begin{keyword}
Capital goods \sep Reliability optimization  \sep Performance-based contracting \sep Life cycle costs
\end{keyword}
\end{frontmatter}
\section{Introduction}

%%%%%%%% the first graph give the main context of the paper
Capital goods are machines or products that are used by manufacturers to produce their end-products or that are used by service organizations to deliver their services. Advanced technical systems such as medical systems, manufacturing systems, defense systems are examples of capital goods that are critical for the operational processes of their customers. System downtime of these capital goods can have serious consequences (e.g., millions of euros of reduced production output, extra waiting time of passengers, failure of military missions) and maintaining these high-tech systems are too challenging for customers to take care of by themselves. As a result, the original equipment manufactures (OEMs) provide after-sale service to their customers to keep the availability of the systems on certain levels through service contracts. Different types of service contracts were mentioned in \citet{Cohen2006}, among which, performance-based contracts (PBC) are novel agreements promising a predetermined level of availability to meet the customers' objectives. Therefore under a PBC, customers pay for services according to the system performance. When the system performance fails to meet the predetermined level of availability, OEMs need to pay a penalty cost to their customers.

%Therefore, customers of these complex systems, such as hospitals, militaries and factories, require high availabilities of these systems. On the other hand, the engineering systems involved in capital goods are becoming more and more complex due to the advancement of technologies. The maintenance and repair tasks are too challenging for customers to take care of by themselves. Thus, after-sale services such as maintenances and repairs are often needed by the customers.

%(service contract and performance based contract: Oliva and Kallenberg (2003), Dennis and Kambil (2003), Cohen et al. (2006), Kim et al. (2007, 2011))

%As a result, integrating services as a major sustainable source of profit has been widely recommended by a large amount of papers in recent decades for original equipment manufacturers (OEMs). A study conducted by Accenture (\citet{Dennis}) shows that after-sale services contribute only 25\% of the total revenue across all manufacturing companies, but are responsible for $40\%\-50\%$ of the profit. Many OEMs thus have been transforming their business strategies from product-oriented to service-oriented(\citet{Cohen2006}). \citet{Oliva} mentioned that by integrating services into their core product offerings OEMs can get extra revenues, high margins, a higher specialization level, and competitive advantage. According to \citet{Kim2007} and \citet{Oliva}, there are mainly two types of service contract in literature: material based contract and performance based contract. After selling a system, under the traditional material-based contract, the OEM is responsible for the repair of the system only within the warranty period, which is often short compared with the entire life cycle of the system. After the warranty period, the OEM will charge the customer for providing spare parts, maintenance, and other services to have high availability of the system. From customers' perspective, this may lead to higher spare parts costs, repair costs and labor costs, whereas system availabilities can be lower than the anticipation of the customer when buying the system. This undesired situation for the customer can be avoided by making better agreements with the OEM when a new system is being bought.
%In reality, when a OEM is manufacturing a capital goods in the design phases, commonly it is facing more than one design plans for each critical components, each design has a different failure rate which is randomly distributed with certain distribution parameters,

%%%%%%%% From the second graph, go to our questions by explainning the three important characteristic:

%%%%%%%% 1) minmize LCC

Under a PBC, one of the OEM's major concern is the life cycle cost (LCC), which is defined as the total cost incurred in the design/development, production, operation, maintenance, support, and final disposition of a system over its anticipated useful life span (\citet{Barringer}). The results of \citet{Oner2007} showed that the summation of maintenance cost and downtime cost is larger than the acquisition cost and constitutes a significant portion of the LCC. These service costs are incurred by system failures which are highly dependent on system designs. Therefore, reliability design decision should consider LCC.

%%%%%%%% 2) interval availability
%For OEMs, it is important to estimate the system availabilities before the launching of systems. By measuring the interval availability of the system, the OEMs can

The customers of capital goods measure the availabilities of these complex systems at the ends of service contract periods. The realized availabilities of the capital goods should meet the required performance levels. According to the PBCs, when the overall downtime of a system exceeds its targeted downtime, the OEMs will pay a penalty cost to their customers for not meeting the target. Therefore, it is important for the OEMs to calculate the probability that the total downtime exceeds the targeted downtime of a given system, so that they can choose the optimal option for system reliability design considering system availability.

%%%%%%%% 3) uncertainty

In reality, engineers have to select a certain design from all possible alternatives for each critical component in a system during the design phase. The outcome of any development process for a certain design is uncertain with respect to the reliability requirement. For example, since the failure mechanisms of some emerging technologies (e.g., Micro-Electro-Mechanical Systems) are complex, it is often difficult to predict the actual reliability behaviors of the critical components before the development. Therefore newly-designed devices have been found to have different component reliabilities than the expectations after the completion of design. The uncertainties in component reliabilities can lead to large deviations of the realized system availabilities from the expected system availabilities (i.e., point estimates for the system availabilities). In this case, the uncertainty in component reliabilities also needs to be considered in the decision making of system reliability design under a PBC.

In this paper, we attempt to solve a system reliability design problem by minimizing the LCC and considering both uncertain component reliability and interval availability under a PBC, which has not been studied yet. The contribution of the paper is as follows: 1) we take uncertainty in the failure rates of the critical components into consideration. The uncertainty in the failure rates is coming from the design phase of an advanced system; 2) in order to reduce the computation time of calculating the total downtime for a certain reliability design, we propose an approximate method to evaluate the total downtime of a given design in negligible time; 3) we compare results from different evaluation methods: stochastic method ignoring the uncertain failure rate distribution, deterministic method using expected total downtime as the actual total downtime and our own model considering both stochastic nature of the number of the system failures and the uncertain failure rates.

The remainder of the paper is organized as follows: in Section 2, we briefly reviewed the related literature. Section 3 gives the model description and model formulation. We proposed an approximation evaluation method in Section 4. And Section 5 different optimization methods has been discussed. The numerical results and managerial insights of evaluation and optimization are give in Section 6. The conclusion and future extension of our research are given in Section 7.
\section{Literature}

\begin{figure}
\centering
\includegraphics[width=0.8\linewidth]{lr1.pdf}
 \caption{Literature review}
 \label{fig:literature}
\end{figure}
According to the characteristics of our problem, we shall briefly review the literatures regarding interval availability, reliability optimization and uncertain reliability as described in \ref{fig:literature}.

As defined by \citet{Nakagawa}, interval availability is the fraction of time that a system is operational during a period of time $[0,T]$. Several methods have been proposed to measure interval availability during a service period in literature. \citet{Takacs} first derived the probability distribution function, the limiting distribution and the moments of the interval availability in closed form. Regarding the computational difficulty, \citet{DeSouza} and \citet{AlHanbali} developed several methods to compute the interval availability numerically.
%
%(LCC Life cycle costs:  \"{O}ner et al. (2007)) ({interval availability}: Al Hanbali and van der Heijden (2013); Carrasco (2004); Kirmani and Hood (2008).)

 For the literatures about reliability optimization, a lot of work have been done in this area since the 1990s (\citet{Kuo}). For example, \citet{Mettas} estimated the minimum required reliability for each component of a system in order to achieve a system reliability goal with minimum cost, and the cost function for each component in this paper has been introduced by other papers as well, such as \citet{Huang}, \citet{Oner2010} and \citet{Jin}. Many paper maximize the system reliability by different techniques, for example, a random search process has been proposed by \citet{Beraha} to assign the optimal reliability to each stage of a multi-stage system, \citet{Hwang} used sequential unconstraint minimization, and \citet{Li} developed a 3-level decomposition approach to allocate the resource among subsystems optimally.

Some papers also built the reliability allocation models to find the optimal warranty policies for systems sold with traditional warranty contracts. For example, to minimize the system LCC, \citet{Zuo1998} used genetic algorithms to solve the optimization problem and \citet{Oner2010} introduced a decision support model to jointly optimize the reliability level and spare parts inventory level of a single component system in the design phase. To maximize the profit, \citet{Huang} propose a model to compute the optimal warranty policy under different market situations.

In most previous works on system reliability optimization problem, all parameters were assumed to be precise. However in reality there is considerable uncertainty and inaccuracy in the estimation of the model parameters, especially the component reliabilities. To measure the uncertain system reliability due to the insufficient component-level failure data, \citet{Coit1997}, \citet{Jinandcoit} and \citet{Ramirez-Marquez2008} estimate the confidence interval of the system reliability for different systems.
To solve the reliability optimization problem considering component reliability uncertainty, \citet{Murthy1998} developed a model to determine the optimal redundancy design considering quality uncertainty due to manufacture variability, and obtained the best tradeoff between the manufacturing cost and warranty cost. In \citet{Murthy2003}, the component uncertain reliability has been modeled by a reliability growth model, and a optimization model has been proposed to find the best tradeoff between the development cost and the warranty cost. \citet{Feizollahi} proposed a reliability design framework to address the uncertain component reliability by using the Min-Max regret (also known as robust deviation) approach and transform the nonlinear programming formulations to a linearized binary version to get the exact solutions. None of the above works considered the interval availability under a PBC.

In this paper, we focus on the cases in which component reliabilities can be selected by adopting different materials, designs, or manufacturing processes.

\section{Model}
%\subsection{Model description}
%$i \in \{1,2,...,\(\lvert I\rvert\) \}$
During the design phase of a system, engineers have to select a certain design from all the possible alternatives for each critical component in the system. Suppose the system is comprised of a set of critical components $I=\{1,2,\dots,\lvert I \rvert\}$. If one of these critical components fails, the system as a whole stops working. For each critical component , one design needs to be selected from possible alternatives denoted by $\{1,2,...,\lvert J_{i} \rvert\}$. Each design candidate in $J_{i}$ has its own uncertain reliability parameters and cost parameters. We aim to find out the optimal combination of designs for the system to minimize the expected LCC over the service period $T$ of a PBC contract.

We assume that the failure process of each of design from each component is independent and follows a Poisson process. Without loss of generality, we exclude the cases when two or more failures happening at the same time, so each time when the system is down it only suffered from one failure. Then the lifetimes of the components are also independent and exponentially distributed. Then for a certain rough design $j$ of component $i$ ($i \in I$, $j \in J_{i}$), we denote its failure rate as $\Lambda_{ij}$. The outcome of any development process for a certain design is uncertain. Therefore, the failure rate $\Lambda_{ij}$ of design $j$ for component $i$ is usually not known for sure before the development of the rough design. We use $f_{\Lambda_{ij}}(.)$ as the probability density function of the random failure rate $\Lambda_{ij}$ before the development of the rough design, which reflects the prior belief/information about the reliability uncertainty of the technologies used in the rough design. In the evaluation of the expected LCC over the service period $T$, these design uncertainties will be taken into account for different combinations of rough designs.

The system will be sold together with a PBC contract over a service period $[0,T]$. The OEM is responsible for all the repairs in $[0,T]$. Moreover the total downtime of the service period should be lower than a predetermined value $D_0$. A penalty cost will be paid by the OEM to compensate the customer if the total downtime exceeds $D_{0}$. As a result, the expected total cost of a system over $[0, T]$ consists of three parts: (a) acquisition cost, (b) repair cost, and (c) penalty cost. A detailed description of the evaluation of these cost elements are given in the following subsections.

%\subsection{Model formulation}
Define binary decision variable $x_{ij}$ as
	\[ x_{ij} = \left \{
	  \begin{array} {l l}
         1 & \textrm {if rough design $j$ for component $i$ is selected,}\\
         0 & \textrm {otherwise.}
		\end {array} \right.\]
 We assume the OEM can only select one design from all the possible candidates for each component, so we have $\sum^{\lvert J_{i}\rvert}_{j=1}{x_{ij}=1}$. And the vector of $x_{ij}$ of a given component $i$, $\boldsymbol{x}_{i}=[\boldsymbol{x}_{i1}, \boldsymbol{x}_{i2},\dots, \boldsymbol{x}_{i\lvert J_{i}\rvert}]$ represents which alternative component design has been chosen for component $i$. While the vector of $\boldsymbol{x}_{i}$ ($i \in I$), $\boldsymbol{x}=[\boldsymbol{x}_{1}, \boldsymbol{x}_{2},\dots, \boldsymbol{x}_{\lvert I \rvert}]$ is the decision variable of the system representing the selection of the alternative design for each component. The OEM is interested in minimizing the expected LCC $\pi(\boldsymbol{x})$, which is the sum of the total design cost $A(\boldsymbol{x})$, the expected system repair cost $R(\boldsymbol{x})$ and the expected penalty cost $P(\boldsymbol{x})$. Due to the randomness of the failure rates $\Lambda_{1}(\boldsymbol{x}_{1}),\Lambda_{2}(\boldsymbol{x}_{2}),...,\Lambda_{\lvert I \rvert}(\boldsymbol{x}_{\lvert I \rvert})$ in rough designs, the expected total life cycle cost $\pi(\boldsymbol{x})$ is random. If the decision maker is risk-neutral, the optimization model of this problem can be formulated as
\begin{eqnarray}
\text{(P)} \hspace{15mm} & min_{\boldsymbol{x}} & \hspace{10mm} \pi(\boldsymbol{x}) \nonumber\\
& \text{ s.t. }&  \hspace{5mm} \sum_{j=1}^{\lvert J_{i}\rvert }{x_{ij}}=1, \hspace{10mm} \text{for all $i$}  \in I \nonumber\\
& & \hspace{5mm} x_{ij} \in \{0,1\}, \hspace{10mm}  \text{for all $i$}  \in I, j \in J_{i}
\end{eqnarray}
where $\pi(\boldsymbol{x})=A(\boldsymbol{x})+R(\boldsymbol{x})+P(\boldsymbol{x})$. Notice that in the above optimization formulation, although we do not include a probability constraint on the distribution of $\pi(\boldsymbol{x})$, the variance of $\pi(\boldsymbol{x})$ still gets penalized by the third cost term $P(\boldsymbol{x})$ in the objective function. This optimization problem is difficult to solve because of the complicated form of the objective function. In the objective function, the expected penalty cost $P(\boldsymbol{x})$ is a multiple integration over the ranges of the random failure rates, which is difficult to calculate. Therefore, in the next section, an approximation method will be proposed to make the evaluation of the objective function easier.

\section{Evaluation}
\subsection{Exact evaluation}

\subsubsection{Acquisition cost}
	
	Let $c_{ij}^{a}$ denote the cost of designing and manufacturing component $i$ according to a rough design $j$ ($i \in I$, $j \in J_{i}$). It includes all the costs incurred to realize a certain rough design of component during the design phase, e.g., human resources, experimental equipment, testing or prototype units, etc. The acquisition cost for component $i$ is given by
\small
\begin{eqnarray}
A_{i}(\boldsymbol{x}_{i})=\sum^{\lvert J_{i} \rvert}_{j=1} {c_{ij}^{a} x_{ij}},
\label{Ai}
\end{eqnarray}
\normalsize
where $\boldsymbol{x}_{i}=[x_{i1},x_{i2},...,x_{i\lvert J_{i}\rvert}]$ represents the selection of rough designs for component $i$.
And the total system acquisition cost is given by
\small
\begin{eqnarray}
A(\boldsymbol{x})=\sum ^{\lvert I \rvert}_{i=1}A_{i}(\boldsymbol{x}_{i})=\sum ^{\lvert I \rvert}_{i=1}\sum^{\lvert J_{i} \rvert}_{j=1} {c_{ij}^{a} x_{ij}}, \label{A}
\end{eqnarray}
\normalsize
where $\boldsymbol{x}$ represents the selection plan of rough designs for all the critical components in the system.
	
\subsubsection{Repair cost}
	
When a failure occurs in period $[0, T]$, a repair will be performed by the OEM. We assign $c^r_{ij}$ as the repair cost for each failure of the $j$th rough design for component $i$ ($i \in \{1,2,...,\lvert I \rvert \}$, $j \in \{1,2,..., \lvert J_{i} \rvert $) respectively. The repair cost $c^r_{ij}$ corresponds to diagnosis cost, replacement cost, and other service costs for each repair. A failure-based policy for maintenance is assumed for this multi-component system in order to evaluate the maintenance cost over the service period $T$. The evaluation of repair cost based on a failure-based policy is relatively accurate and conservative. Let $S_{i}(\boldsymbol{x}_{i})$ denote the total number of failures for component $i$ during $[0,T]$. Under such a failure-based policy and the assumption that the lifetimes of components are exponentially distributed, the expected number of repairs for component $i$ during $[0,T]$, $\mathbb{E}[S_{i}(\boldsymbol{x}_{i})]$ is given by:
%$E[N_{i}(T)]$
\small
\begin {eqnarray}
\mathbb{E}\bigg[S_{i}(\boldsymbol{x}_{i})\bigg]=\mathbb{E}\bigg[\Lambda_{i}(\boldsymbol{x}_{i})T\bigg] =\sum_{j=1}^{\rvert J_{i} \lvert}{\mathbb{E}(\Lambda_{ij}T)x_{ij}}=\sum_{j=1}^{\rvert J_{i} \lvert}{\mu_{ij}T}x_{ij}
\end {eqnarray}
\normalsize

Where $\Lambda_{ij}$ is the random failure rates for the $j$th design of component $i$, while $\mu_{ij}$ and $\sigma_{ij}$ are the expectation and standard deviation of $\Lambda_{ij}$. $\Lambda_{i}(\boldsymbol{x}_{i})=\sum_{j=1}^{\rvert J_{i} \lvert}{\Lambda_{ij}x_{ij}}$ is the random failure rate of component $i$ given a certain rough design $\boldsymbol{x}_{i}$. Then the expected repair cost for component $i$, $R_{i}(\boldsymbol{x}_{i})$ is expressed by:
\small
\begin {eqnarray}
R_{i}(\boldsymbol{x}_{i}) = \sum_{j=1}^{\rvert J_{i} \lvert}{\mathbb{E}(\Lambda_{ij}Tc^r_{ij})x_{ij}}= \sum_{j=1}^{\rvert J_{i} \lvert}{\mu_{ij}Tc^r_{ij}}x_{ij}. \label{ERi}
\end {eqnarray}
\normalsize

Given that the failure processes of all the critical components are independent of each other, the expected system repair cost $R(\boldsymbol{x})$ in $[0,T]$ is given as:
%is the sum of $R_{i}(\boldsymbol{x_i}), \forall i \in \{1,2,...,\rvert I \lvert\}$. The expectation of $R(\boldsymbol{x})$ over all the distributions of $\Lambda_{1}(\boldsymbol{x_{1}}),\Lambda_{2}(\boldsymbol{x_{2}}),..., \Lambda_{\rvert J_{i} \lvert}(\boldsymbol{x_{\rvert J_{i}\lvert}})$
\small
\begin {eqnarray}
 R(\boldsymbol{x}) = \sum_{i=1}^{n}{R_{i}(\boldsymbol{x}_{i})} = \sum_{i=1}^{\rvert I \lvert}\sum_{j=1}^{\rvert J_{i} \lvert}{\mu_{ij}Tc^r_{ij}}x_{ij}.\label{ER}
\end {eqnarray}
\normalsize

%%%%%%%%%%%remove the variance of the system repair time, R(x) already means expected repair time. var(R(x)) seems really weird. And var(R(x)) is not mentioned later on.
%The variance of the expected system repair cost with respect to the random failure rates can be expressed as
%\begin {eqnarray}
% Var_{\Lambda(\boldsymbol{x})} \bigg[ R(\boldsymbol{x}) \bigg]  &=&Var_{\Lambda(\boldsymbol{x})} \bigg[ \sum_{i=1}^{n}R_{i}(\boldsymbol{x_{i}}) \bigg]
%= \sum_{i=1}^{n} Var_{\Lambda_i(\boldsymbol{x_{i}})}\bigg[R_{i}(\boldsymbol{x_i})\bigg] \nonumber \\
% &=& \sum_{i=1}^{n} Var_{\Lambda_i(\boldsymbol{x_{i}})}(\sum_{j=1}^{m_{i}}{\Lambda_{ij}c_r^{ij}x_{ij}}T) \nonumber\\
%&=& \sum_{i=1}^{n} \sum_{j=1}^{m_{i}}{(c_r^{ij}x_{ij}}T)^2 Var(\Lambda_{ij}).
%\end {eqnarray}
%For a signal component $i$, its variance of its repair time $Var[R_{i}(x_{i})]$ is:
%\begin{eqnarray}
%Var[R_{i}(x_{i})] = \sum_{j=1}^{\rvert J_{i} \lvert}{Var(\Lambda_{ij}Tc_{ij}^{r})}x_{ij}=\sum_{j=1}^{\rvert J_{i} \lvert}{Var(\Lambda_{ij})(Tc^{r}_{ij})^{2}x_{ij}}
%\end{eqnarray}
%The

\subsubsection{Penalty cost}
A period of system downtime $r_{ij}(r_{ij}<<T)$ will be incurred due to a random failure of component $i$ with rough design $j$ in the system ($i \in \{1,2,...,\rvert I \lvert \}$, $j \in \{1,2,...,\rvert J_{i} \lvert \}$).
Notice that while evaluating the repair costs in the previous section we ignore the downtime since the downtime is usually negligible compared with the service period $T$, for the same reason, when we computing the penalty cost, we ignore the downtime as well. And we also exclude the probability that two or more components failed at the same time, so that each time when the system is down, it is only because one component is down.
However, under a PBC contract, when the total system downtime over the service period $T$ exceeds $D_0$, a penalty cost should be paid by the OEM to customers with a rate $c_p$. $D_0$ is at the same time scale as $r_{ij}$. We assume the system downtime of each failure varies among different components with different rough designs. Hence the total system downtime $D{(\boldsymbol{x})}$ over the service period $T$ is dependent on the number of failures $S_{i}(\boldsymbol{x}_{i})$ and the repair time per failure $r_{i}(\boldsymbol{x}_{i})$ for component $i$,$\forall i\in \{1,\dots,n\}$ in $[0,T]$. The repair time per failure for component $i$, $r_{i}(\boldsymbol{x}_{i})=\sum_{j=1}^{\rvert J_{i} \lvert}{r_{ij}x_{ij}}$, is a fixed value after the selection plan for component $i$ has been made. Notice that the number of failures from component $i$, $S_{i}(\boldsymbol{x}_{i})$, is a Poisson distributed random variable, whose distribution is given as
\small
\begin{eqnarray}
Pr\bigg[S_{i}(\boldsymbol{x}_{i})=s_{i}\bigg] &=&\sum^{\rvert J_{i} \lvert}_{j=1}{x_{ij}Pr(S_{ij}=s_{i})} \nonumber\\
&=&\sum^{\rvert J_{i} \lvert}_{j=1}{x_{ij}\int^{\infty}_{0}Pr(S_{ij}=s_{i}|\Lambda_{ij}=\lambda_{ij})f_{\Lambda_{ij}}(\lambda_{ij})d\lambda_{ij}} \nonumber\\
&=&\sum^{\rvert J_{i} \lvert}_{j=1}{x_{ij}\int^{\infty}_{0}{\frac{e^{-\lambda_{ij}T}(\lambda_{ij}T)^{s_{i}}}{s_{i}!}f_{\Lambda_{ij}}(\lambda_{ij})}d\lambda_{ij}}
\end{eqnarray}
\normalsize
%And the system downtime can be expressed as
%\small
%\begin{eqnarray}
%D(\boldsymbol{x}) &=& \sum_{s_{1}=0}^{\infty}{Pr\bigg[S_{1}(\boldsymbol{x}_{1})=s_{1}\bigg]}\dots\sum_{s_{\rvert I \lvert}=0}^{\infty}{Pr\bigg[S_{\rvert I \lvert}(\boldsymbol{x}_{\rvert I \lvert})=s_{\rvert I \lvert}\bigg]} \bigg[\sum_{i=1}^{\rvert I \lvert}{s_{i}r_{i}(\boldsymbol{x}_{i})}\bigg] \label{systemdowntime}
%\end{eqnarray}
%\normalsize
According to the service contract, the OEM should pay a penalty cost to the customer. Since the failure rates $\Lambda_{1}(\boldsymbol{x}_{1}),\Lambda_{2}(\boldsymbol{x}_{2}),...,\Lambda_{n}(\boldsymbol{x}_{n})$ are random variables, the expected penalty cost is a random variable as well. Without loss of generality, we assume the failure rates are continuous random variables, with probability density functions $f_{\Lambda_{ij}}(.)$ over region $\mathcal{O}_{ij}$. Then the expected penalty cost due to extra downtime exceeding $D_{0}$ is given as
\small
\begin{eqnarray}
P(\boldsymbol{x})& = & \mathbb{E}\bigg\{\bigg[D(\boldsymbol{x})-D_{0}\bigg]^{+} c_{p} \bigg\} \nonumber\\
&=&\sum_{s_{1}=0}^{\infty}\sum_{s_{i}=0}^{\infty}\dots\sum_{s_{\rvert I \lvert}=0}^{\infty}{\prod_{i=1}^{\rvert I \lvert} {Pr\bigg[S_{i}(\boldsymbol{x}_{i})=s_{i}\bigg]}} \bigg[\sum_{i=1}^{\rvert I \lvert}{s_{i}r_{i}(\boldsymbol{x}_{i})}-D_{0}\bigg]^{+}c_{p} \nonumber\\
&=& \sum_{s_{1}=0}^{\infty}\sum_{s_{i}=0}^{\infty}\dots\sum_{s_{\rvert I \lvert}=0}^{\infty}{\prod_{i=1}^{\rvert I \lvert}{\sum_{j=1}^{\rvert J_{\rvert i \lvert} \lvert}{x_{ij}\int_{0}^{\infty}{\frac{e^{-\lambda_{ij}T}(\lambda_{ij}T)^{s_{i}}}{s_{i}!}
f_{\Lambda_{ij}}(\lambda_{ij})d\lambda_{ij}}}}}
\label{penaltycost}
\end{eqnarray}

\normalsize
\subsection{Approximate evaluation}
In this section, we are going to explain how to evaluate a given selection plan of rough designs for all the component in the system approximately. For a given policy $\boldsymbol{\underline{x}}=[\boldsymbol{\underline{x}}_{1},\boldsymbol{\underline{x}}_{2},\dots,\boldsymbol{\underline{x}}_{\lvert I \rvert}]$, the design cost $A(\boldsymbol{\underline{x}})$ and the expected repair cost $R(\boldsymbol{\underline{x}})$ can be determined from Equation \eqref{A} and \eqref{ER}. These two cost terms are linear functions of the decision variables $\underline{\boldsymbol{x}}=[\boldsymbol{\underline{x}}_{1},\boldsymbol{\underline{x}}_{2},\dots,\boldsymbol{\underline{x}}_{\lvert I \rvert}]$.

For the exact evaluation of the expected penalty cost $P(\boldsymbol{\underline{x}})$, we will suffer from the ``curse of dimensionality" when the number of critical components becomes large, since each critical component contributes a dimension in computing the convolution and integration in Equation \eqref{penaltycost}. The computation time will become intractable as the number of critical components grows. From Equation \eqref{systemdowntime}, we can observe that there are two levels of uncertainty existing in $D(\boldsymbol{\underline{x}})$ throughout $[0, T]$. The first level of uncertainty originates from the number of failures $S_{i}(\boldsymbol{\underline{x}})$ ($i \in \{1,2,...,\lvert I \rvert\}$), which is a Poisson distributed random variable. The second level of uncertainty comes from the failure rates $\lambda_{ij}$ ($i \in \{1,2,\dots,\lvert I \rvert\}$, $j \in \{1,2,\dots, \lvert J_{i} \rvert\}$), which is a generally distributed random variable. With the consideration of the stochastic nature of the system downtime $D(\boldsymbol{\underline{x}})$ and the real life situation, we introduce three type of approximation methods to estimate the expected penalty cost, which vary in dealing with the uncertainty levels of $D(\boldsymbol{\underline{x}})$. As is commonly used in the real world, in the first evaluation method, we use the expected the downtime as the actual downtime, which ignore both levels of the uncertainty. According to current literatures, for example,  the uncertainty existing in the failure rates are usually ignored, so in the second evaluation method, we only consider the uncertainty of the number of failures of the system. While for the third evaluation method, we address both uncertainty levels of $D(\boldsymbol{\underline{x}})$ by using the two-moment fit method. The comparison of these methods will be further shown in Section \ref{sec:numerical results}.

To drive the first and second moment of $D(\boldsymbol{\underline{x}})$, first, for the total downtime of the $j$th design in component $i$ in $[0, T]$, the first moment is given as:
\small
\begin{eqnarray}
\mathbb{E}(D_{ij}) &=& \int_{\lambda_{ij}\in \mathcal O_{ij}}\mathbb{E}\bigg[D_{ij} \bigg\vert \Lambda_{ij}=\lambda_{ij}\bigg]f_{\Lambda_{ij}}(\lambda_{ij})d\lambda_{ij} \nonumber\\
 &=& \int_{\lambda_{ij}\in \mathcal O_{ij} } \lambda_{ij}T r_{ij}f_{\Lambda_{ij}}(\lambda_{ij})d\lambda_{ij} \nonumber\\
 &=& \mu_{ij} T r_{ij}
\end{eqnarray}
\normalsize
By using the moment generating function of $D_{ij}$, we have the second moment and variance written as:
\small
\begin{eqnarray}
\mathbb{E}(D^{2}_{ij}) &=& \int_{\lambda_{ij}\in \mathcal O_{ij}}\mathbb{E}\bigg[D^{2}_{ij} \bigg\vert \Lambda_{ij}=\lambda_{ij}\bigg]f_{\Lambda_{ij}}(\lambda_{ij})d\lambda_{ij}  \nonumber\\
&=& \int_{\lambda_{ij}\in \mathcal O_{ij}} {r^{2}_{ij}\lambda_{ij}T(1+\lambda_{ij}T)f_{\Lambda_{ij}}(\lambda_{ij})d\lambda_{ij}} \nonumber\\
&=& r^{2}_{ij}T\mu_{ij} + r^{2}_{ij}T^{2}(\sigma^{2}_{ij}+\mu^{2}_{ij}) \\
\textrm{Var}(D_{ij})&=&\mathbb{E}\bigg[D^{2}_{ij}\bigg] - \bigg(\mathbb{E}[D_{ij}]\bigg)^{2}=r^{2}_{ij}[\mu_{ij}T + T^{2}\sigma^{2}_{ij}]
%&=& r^{2}_{ij}\mu_{ij}T + r^{2}_{ij}T^{2}(\sigma^{2}_{ij}+\mu^{2}_{ij})-r_{ij}^{2}T^{2}\mu^{2}_{ij}\nonumber\\
\end{eqnarray}
\normalsize
Then, for a single component $i$, we have:
\small
\begin{eqnarray}
D_{i}(\boldsymbol{\underline{x}}_{i}) &=& \sum_{j=1}^{\lvert J_{i}\rvert}{D_{ij}\underline{x}_{ij}}\\
\mathbb{E}[D_{i}(\boldsymbol{\underline{x}}_{i})] &=&\sum_{j=1}^{\lvert J_{i} \rvert}{r_{ij}\mu_{ij}T\underline{x}_{ij}} \\
\textrm{Var}[D_{i}(\boldsymbol{\underline{x}}_{i})]&=&\sum_{j=1}^{\lvert J_{i} \rvert}{r_{ij}^{2}[T^{2}\sigma^{2}_{ij}+T\mu_{ij}]\underline{x}_{ij}}
\end{eqnarray}
\normalsize
Finally, for the total downtime of the system in $[0, T]$:
\small
\begin{eqnarray}
D(\boldsymbol{\underline{x}}) &=& \sum_{i=1}^{\lvert I \rvert}D_{i}(\boldsymbol{\underline{x}}_{i})
=\sum_{i=1}^{\lvert I \rvert}\sum_{j=1}^{\lvert J_{i}\rvert}{D_{ij}\underline{x}_{ij}}  \\
\mu_{D}(\boldsymbol{\underline{x}})&=&\mathbb{E}[D(\boldsymbol{\underline{x}})] = \sum^{\lvert I \rvert}_{i=1}\mathbb{E}[D_{i}(\boldsymbol{\underline{x}}_{i})] = \sum^{\lvert I \rvert}_{i=1} \sum_{j=1}^{\lvert J_{i} \rvert}{r_{ij}\mu_{ij}T\underline{x}_{ij}} \label{expdowntime}\\
\sigma^{2}_{D}(\boldsymbol{\underline{x}})&=&\textrm{Var}[D(\boldsymbol{\underline{x}})] = \sum_{i=1}^{\lvert I \rvert} \sum_{j=1}^{\lvert J_{i} \rvert}\textrm{Var}[D_{i}(\boldsymbol{\underline{x}}_{i})] = \sum_{i=1}^{\lvert I \rvert}\sum_{j=1}^{\lvert J_{i} \rvert}r_{ij}^{2}[T^{2}\sigma^{2}_{ij}+T\mu_{ij}]\underline{x}_{ij} \label{vardowntime}
\end{eqnarray}
\normalsize

\subsubsection{One-moment method}

The most direct way of approximating the system downtime is to use expected downtime instead of the actual downtime. According to Equation \eqref{expdowntime}, one-moment fit method use $\mathbb{E}[D(\boldsymbol{\underline{x}})]$ as $D(\boldsymbol{\underline{x}})$, then we have the first evaluation of system downtime $D_{A1}(\boldsymbol{\underline{x}})$ described as:
\small
\begin{eqnarray}
D_{A1}(\boldsymbol{\underline{x}}) = \sum^{\lvert I \rvert}_{i=1} \sum_{j=1}^{\lvert J_{i} \rvert}{r_{ij}\mu_{ij}T\underline{x}_{ij}}
\label{approximation1}
\end{eqnarray}
\normalsize
With $D_{A1}$ as the actual downtime, the exceeded downtime $D^{E}$ can be approximated as:
\begin{eqnarray}
D^{E}_{A1}(\boldsymbol{\underline{x}}) =\mathbb{E}\bigg\{\bigg[D(\boldsymbol{\underline{x}})-D_{0}\bigg]^{+}\bigg\} = \bigg[D_{A1}(\boldsymbol{\underline{x}})-D_{0} \bigg]^{+} \label{penapproximation1}
\end{eqnarray}
\subsubsection{Fixed failure rate method}
In current literature, when researchers are dealing with certain reliability optimization problems, for example \citet{Mettas} \citet{Oner2010} and \citet{Huang}, they did not consider the uncertainty of $\lambda_{ij}$ ($i \in I$, $j \in \rvert J_{i} \lvert$). So for the second approximation evaluation method, given that the lifetimes of the components are exponentially distributed, we will simply assume $\lambda_{ij}$ ($i \in I$, $j \in \rvert J_{i} \lvert$) is a constant. $D^{E}(\boldsymbol{\underline{x}})$ can be approximated as $D^{E}_{A2}(\boldsymbol{\underline{x}})$:
\small
\begin{eqnarray}
D^{E}_{A2}(\boldsymbol{\underline{x}}) &=&\sum_{s_{1}=0}^{\infty}\sum_{s_{i}=0}^{\infty}\dots\sum_{s_{\rvert I \lvert}=0}^{\infty}{\prod_{i=1}^{\rvert I \lvert} {Pr\bigg[S_{i}(\boldsymbol{x}_{i})=s_{i}\bigg]}} \bigg[\sum_{i=1}^{\rvert I \lvert}{s_{i}r_{i}(\boldsymbol{x}_{i})}-D_{0}\bigg]^{+}c_{p} \nonumber\\
&=& \sum_{s_{1}=0}^{\infty}\sum_{s_{i}=0}^{\infty}\dots\sum_{s_{\rvert I \lvert}=0}^{\infty}{\prod_{i=1}^{\rvert I \lvert} {x_{ij}\frac{e^{-\lambda_{ij}T}(\lambda_{ij}T)^{s_{i}}}{s_{i}!}}}\bigg[\sum_{i=1}^{\rvert I \lvert}{s_{i}r_{i}(\boldsymbol{x}_{i})}-D_{0}\bigg]^{+}c_{p}
\end{eqnarray}
\normalsize

\subsubsection{Two-moment fit method}

To approximate both the uncertainty of the failure rate as well as the number of failures, we find an approximation method to calculate the distribution of the system downtime $D(\underline{\boldsymbol{x}})$. As we mentioned before, the total downtime $D(\underline{\boldsymbol{x}})$ is the summation of the downtime for all critical components. The number of failures for each component is Poisson distributed with an uncertain parameter. In this approximate method, we approximate the downtime by fitting a mixed Erlang distribution to the first two moments of $D(\underline{\boldsymbol{x}})$. We got the first moment and variance of $D(\underline{\boldsymbol{x}})$, from Equation \eqref{expdowntime} and Equation \eqref{vardowntime}. Then the coefficient of variation of $D(\underline{\boldsymbol{x}})$ is given by
\small
\begin{eqnarray}
c_{v}(\boldsymbol{x}) &=& \frac{\sigma_{D}(\boldsymbol{x})}{\mu_{D}(\boldsymbol{x})} = \frac{\sqrt{\sum_{i=1}^{\lvert I \rvert}\sum_{j=1}^{\lvert J_{i} \rvert}r_{ij}^{2}[T^{2}\sigma^{2}_{ij}+T\mu_{ij}]\underline{x}_{ij}}}{\sum^{\lvert I \rvert}_{i=1} \sum_{j=1}^{\lvert J_{i} \rvert}{r_{ij}\mu_{ij}T\underline{x}_{ij}}} \label{cv}
\end{eqnarray}

\normalsize
Given that $\mu_{D}>0$, and $0<c_{v}\leq 1$, according to Tijms 1994, we fit the downtime distribution to an Erlang$(k-1,k)$ distribution with parameters$(k,\theta,q_{E})$ such that the first two moments of $D(\boldsymbol{x})$ equal the first two moments of the Erlang $(k-1,k)$ distribution. Thus the parameters of the Erlang $(k-1,k)$ distribution can be obtained as
\small
\begin{eqnarray}
&&k(\boldsymbol{x}) = \lceil \frac{1}{c_{v}^{2}(\boldsymbol{x})} \rceil, \label{k1}\\
&&q_{E}(\boldsymbol{x})= \frac{1}{1+c^{2}_{v}(\boldsymbol{x})}\bigg[k(\boldsymbol{x})c^{2}_{v}(\boldsymbol{x})-\sqrt{k(\boldsymbol{x})\big[1+c^{2}_{v}(\boldsymbol{x})\big]-k^{2}(\boldsymbol{x})c^{2}_{v}(\boldsymbol{x})} \bigg], \label{q1}\\
&&\theta(\boldsymbol{x}) = \frac{k(\boldsymbol{x})-q_{E}(\boldsymbol{x})}{\mu_{D}(\boldsymbol{x})}. \label{theta1}
\end{eqnarray}
\normalsize
Then for random failure rates $\Lambda_{1}(\boldsymbol{x_{1}})$, $\Lambda_{2}(\boldsymbol{x_{2}})$,..., $\Lambda_{n}(\boldsymbol{x_{n}})$ the expected exceeding total downtime and expected penalty costs can be approximated by
\begin{eqnarray}
\small
D_{A3}^{E}(\boldsymbol{x})=\mathbb{E}\bigg\{\big[D(\boldsymbol{x})-D_{0}\big]^{+}\bigg\}
%&&=(\frac{k-q}{\theta}-D_{0})\sum_{j=0}^{k-1}{\frac{(\theta(\boldsymbol{x})D_{0})^j}{j!}e^{-\theta(\boldsymbol{x})D_{0}}}\nonumber\\
&=&\bigg[\frac{k(\boldsymbol{x})-q_{E}(\boldsymbol{x})}{\theta(\boldsymbol{x})}-D_{0}\bigg]\sum_{j=0}^{k(\boldsymbol{x})-2}{\frac{\big[\theta(\boldsymbol{x}) D_{0}\big]^j}{j!}e^{-\theta(\boldsymbol{x})D_{0}}}\nonumber\\
&&+\bigg[\frac{k(\boldsymbol{x})-q_{E}(\boldsymbol{x})}{\theta(\boldsymbol{x})}\bigg]\frac{\big[\theta(\boldsymbol{x})D_{0}\big]^{k(\boldsymbol{x})-1}}{\big[k(\boldsymbol{x})-1\big]!}e^{-\theta(\boldsymbol{x})D_{0}}.
\label{EXD1}
\end{eqnarray}
\normalsize
The derivation is given in Appendix \ref{appendix:erlongk-1}.

If $c_{v} \geq 1$, we fit the downtime distribution to an Hyperexponential distribution with parameters$(\theta_{1},\theta_{2}, q_{H})$ such that the first two moments of $D(\boldsymbol{x})$ equal the first two moments of the Hyperexponential distribution. Thus the parameters of the Hyperexponential distribution can be obtained as
\begin{eqnarray}
     \theta_{1}(\boldsymbol{x}) &=& \frac{2}{\mu_{D}(\boldsymbol{x})}\bigg(1+\sqrt{\frac{c^{2}_{v}(\boldsymbol{x})-\frac{1}{2}}{c^{2}_{v}(\boldsymbol{x})+1}} \bigg), \label{theta11}\\
     \theta_{2}(\boldsymbol{x}) &=& \frac{4}{\mu_{D}(\boldsymbol{x})} - \theta_{1}(\boldsymbol{x}), \label{theta12}\\
     q_{H}(\boldsymbol{x}) &=& \frac{\theta_1(\boldsymbol{x})(\theta_2(\boldsymbol{x})\mu_{D}(\boldsymbol{x})-1)}{\theta_2(\boldsymbol{x}) -\theta_1(\boldsymbol{x})} \label{q2}
\end{eqnarray}
Then the expected exceeding total downtime can be approximated by
\begin{eqnarray}
D_{A3'}^{E}(\boldsymbol{x}) =\frac{q_{H}(\boldsymbol{x})}{\theta_{1}(\boldsymbol{x})} e^{-\theta_{1}(\boldsymbol{x}) D_0 } + \frac{1-q_{H}(\boldsymbol{x})}{\theta_{2}(\boldsymbol{x})} e^{-\theta_{2}(\boldsymbol{x}) D_0} \label{EXD2}
\end{eqnarray}
The derivation can be found in Appendix \ref{appendix:hyperexponential}.


The procedure of the approximation evaluation method is illustrated in the following algorithm.

\textbf{Algorithm 1}
\label{Algorithm1}
\begin{description}
\item[Step 1] Compute the $\mu_{D}(\boldsymbol{x})$, $\sigma^{2}_{D}(\boldsymbol{x})$ and $c_{v}(\boldsymbol{x})$ of the downtime distribution, check the value of $c_{v}(\boldsymbol{x})$: if $0<c_{v}(\boldsymbol{x}) \leq 1$, go to step 2; if $c_{v}(\boldsymbol{x}) > 1$, go to step 3.
\item[Step 2] Fit the first two moments of an Erlang$(k-1, k)$ distribution to be equal to the first two moments of the downtime distribution.
 \begin{description}
 \item[Step 2-a] Let $k(\boldsymbol{x})$, $\theta(\boldsymbol{x})$ and $q_{E}(\boldsymbol{x})$ be the parameters of the fitted Erlang$(k-1,k)$ distribution, and compute the values of $k(\boldsymbol{x})$, $\theta(\boldsymbol{x})$ and $q_{E}(\boldsymbol{x})$ according to Equation \eqref{k1},\eqref{q1} and \eqref{theta1}.
 \item[Step 2-b] Calculate the expected exceeding total downtime $D_{E1}^A(\boldsymbol{x})$ according to Equation \eqref{EXD1}.
\end{description}
\item[Step 3] Fit the first two moments of a Hyperexponential distribution to be equal to the first two moments of the downtime distribution.

\begin{description}
 \item[Step 3-a] Let $\theta_{1}(\boldsymbol{x})$, $\theta_{2}(\boldsymbol{x})$ and $q_{H}(\boldsymbol{x})$ be the parameters of the fitted Hyperexponential distribution, compute the values of these parameters according to Equation \eqref{theta11}, \eqref{theta12} and \eqref{q2}.
 \item[Step 3-b] Compute the expected exceeding total downtime $D_{E2}^A(\boldsymbol{x})$ according to Equation \eqref{EXD2} .
\end{description}


\end{description}


%\section{Optimization}

%In the previous section, we have discussed how a given policy, which is the selection of rough designs for all the critical components in the system can be evaluated in an approximate way. In this section, we will describe a method of finding a feasible policy for problem (P) with as low life cycle costs as possible. The problem is formulated as a binary integer programming with a nonlinear objective function.
%which is equivalent to a knapsack problem with multiple-choice constraints, so that is $NP$-hard (Garey and Johnson 1979).




\section{Computational results}
\label{sec:numerical results}

\subsection{Accuracy of the approximation}
\subsubsection{Test bed}
To assess the accuracy the three evaluation methods mentioned in the previous section, we compare the evaluation results of these methods with the simulation results. Our simulation results are generated by using Monte Carlo simulation method, the simulation procedure are mentioned in detail in Appendices \ref{MCP}, in which the exceeded downtime $D^{E}_{S}$ is computed as well as the gaps between $D^{E}_S$ and the exceeded downtime from different evaluation methods, $D^{E}_{A1}$, $D^{E}_{A2}$ and $D^{E}_{A3}$. A full factorial test bed is set up to show the accuracy of the evaluation procedures under different parameter settings. We investigate the effect of three factors: the number of the critical components $n$, coefficient of variation $c_{v}$ of $\lambda_{i}(\underline{\boldsymbol{x}}_{i})$ and the downtime budget factor $D_{f}$. Notice that $\lambda_{i}(\underline{\boldsymbol{x}}_{i})$,   $\mu_{i}(\underline{\boldsymbol{x}}_{i})$ and $r_{i}(\underline{\boldsymbol{x}}_{i})$ are functions of the given design $\underline{\boldsymbol{x}}_{i}$, we will treat them as parameters $\lambda_{i}$, $\mu_{i}$ and $r_{i}$ of in the evaluation. Similarly, $\sigma_{i}(\underline{\boldsymbol{x}}_{i})$ is also considered a parameter $\sigma_{i}$ computed by $c_{v}\mu_{i}$. We generated 210 instances by all combinations of each choice of the three factors. The values of choices for each factor are shown in Table \ref{tab:evaluationtestbedps}. %In the test bed, the factor $D_{\gamma}$ is a coefficient to generate different values of $D_0$ by the following expression,
\begin{table}[htbp]
\small
  \centering
  \caption{The parameter setting of the test bed}
    \begin{tabular}{lll}
    \toprule
  $n$ & $c_{v}$ & $D_{f}$\\
    \midrule
    5, 25, 50, 75, 100 & 0.2, 0.5, 0.8, 1.1, 1.4, 1.7 & 1, 1.05, 1.1, 1.15, 1.2, 1.25, 1.3 \\
  \bottomrule
    \end{tabular}%
  \label{tab:evaluationtestbedps}%
\end{table}

%Similarly, for $\mu_{i}(\underline{\boldsymbol{x}}_{i})$ and $r_{i}(\underline{\boldsymbol{x}}_{i})$ in the calculation of $D^{E}_{A1}(\underline{\boldsymbol{x}})$ and $D^{E}_{S}(\underline{\boldsymbol{x}})$, we will also treat them as parameters ($\mu_{i} , r_{i}$) of the approximation models or simulation model.
 In the test bed the factor $D_{f}$ is a coefficient to generate different values of $D_{0}$ by the following expression,
 \begin{eqnarray}
 D_{0} = D_{f}\sum_{i=1}^{n}{\mu_{i} r_{i} T}, \label{D0}
\end{eqnarray}
where $\sum_{i=1}^{n}{\mu_{i} r_{i} T}$ is the expected total downtime. Thus, if $D_{f}$ is one, the targeted downtime $D_0$ is set to be equal to the expected total downtime. The setting of the fixed parameters in the test bed is given in Table \ref{tab:testbedmur}. $r_{i}$ varies for different $i$ by taking a value from {1, 3, 5}. $\mu_{i}$ varies for different $i$ as a sequence. We assume $\lambda_{i}$ $i \in \rvert I \lvert$ is lognormally distributed.

For the one-moment fit method, it is apparent that when $D_{f} \geq 1$, the exceeded $D^{E}_{A1} = 0$ under all the 210 instances for each distribution. For the fixed-failure rate method, since the randomness of the failure rates are not considered, $D^{E}_{A2}$ is only related to $n$ and $D_{f}$, so only 35 instances for each distribution is computed, to compare the gap between $D^{E}_{A2}$ and $D^{E}_{S}$ under all the 210 parameter settings, we use one identical value of $D^{E}_{A2}$ for different $c_{v}$ under the same settings of ($n$, $D_{f}$).

\begin{table}[htbp]
\small
  \centering
  \caption{Parameter values for $\mu_{i}$ and $r_{i}$, $i=\{1,2,...,n\}$}
    \begin{tabular}{llll}
    \toprule
    $n$ & $T$ & $\mu_{i}$ &  $r_{i}$\\
    \midrule
    5, 25, 50, 75, 100   &10& $\{0.200,...,0.200-(i-1)\frac{0.18}{n-1},...,0.02\}$ &$\{1,3,5,1,3,5,...\}$\\
    \bottomrule
    \end{tabular}%
  \label{tab:testbedmur}%
\end{table}

\subsubsection{Results and managerial insights}

We summarize the results of the test bed in Table \ref{tab:summaryevatestbed}. To see how the approximation results deviate from the simulation results for each instance, we first compute the proportion of the expected exceeding downtime in the targeted total downtime, i.e., $D_{A1}^{E}/D_0$ for the approximation model and $D_{S}^{E}/D_0$ for the simulation model, as well as the confidence intervals of the simulation results. The confidence intervals of all the simulation results are relatively small, which shows the accuracy of our simulation results. Then the accuracy of our approximation is assessed by the gaps between $D_{A1}^{E}/D_0$, $D_{A2}^{E}/D_0$, $D_{A3}^{E}/D_0$ and $D_{S}^{E}/D_0$. For the one-moment fit method, the average gap is $7.39\%$ and the max gap is $34.28\%$; the average and max gap for the fixed-failure method is $3.11$ and $14.12\%$ respectively. While for the two-moment fit method the average gap is $0.42\%$ and the maximum gap is $5.46\%$. From these results, we can get the conclusion that the two-moment fit method is relatively accurate under different parameter settings.

 The two-moment fit methods performs the best among all the method. The average gap of the two-moment fit method is $0.42\%$. The one-moment method has the largest average and max gaps, while the two-moment fit method is the most accurate method. The average gap for
 our approximation method is more accurate when $n$ is large (e.g., 50 or 100). This is due to the fact that the total downtime is the sum of $n$ independent random variables, and when $n$ is large the total downtime converges in distribution to a normal random variable regardless of the individual underlying distributions. Note that the computation times of the approximation models for all the instances are negligible compared with the simulation model. With $D_{f}$ increases, the accuracy of the approximation increase generally, given that higher $D_{f}$ has lower number of failures, which results in a low uncertainty of number of failures. Because the one moment method did not include the uncertainty of number of failures, it has the largest gap. While $c_v$ affects the accuracy of the evaluation in an opposite way, with the increase of $c_v$, both the average and max gap of each methods are increasing. This is because when the $c_v$ becomes larger, $\sigma_{i}$ ($ i\in \rvert I \lvert $) becomes larger as well, which increase the variation of $\lambda_{i}$, in other words, this increase the uncertainty of $\lambda_{i}$. Give that the two-moment fit method has already include this type of uncertainty, the related gap did not increase a lot, while the gap of the other two methods changed a lot.

   In order to better demonstrate the accuracy of the two-moment fit method, we also compare the probability density functions of the downtime distribution estimated from the simulation model with the ones estimated from the approximation model, as shown in Figure \ref{fig:lognormal}. It is obvious that the downtime distributions estimated from the simulation model are approximately the same as the ones estimated from the two moment fit model for various settings of $n$ and $c_{v}$. We also conduct a second full factorial test bed with the same parameter setting but under the assumption that $\lambda_{i}$ is uniformly distributed. The numerical results are similar to the first test bed.
% Table generated by Excel2LaTeX from sheet 'Jan17erlong'
\begin{table}[htbp]
\small
  \centering
    \caption{Average gap and maximum gap between the simulation results and three evaluation methods}
    \begin{tabular}{lrrrrrr}
    \toprule
    & \multicolumn{2}{c}{One-moment method} & \multicolumn{2}{c}{Fixed-failure rate method} & \multicolumn{2}{c}{Two-moment fit method}  \\
    & \multicolumn{1}{c}{avg Gap} & \multicolumn{1}{c}{max Gap} & \multicolumn{1}{c}{avg Gap} & \multicolumn{1}{c}{max Gap} & \multicolumn{1}{c}{avg Gap} & \multicolumn{1}{c}{max Gap} \\
    \midrule
    $\Lambda$ & 7.39\% & 34.28\% & 3.11\% & 14.12\% & 0.42\% & 5.46\% \\
    $\Lambda_{n_{5}}$ & 19.65\% & 34.28\% & 6.74\% & 14.12\% & 1.51\% & 5.46\% \\
    $\Lambda_{n_{25}}$ & 7.19\% & 17.23\% & 3.42\% & 8.47\% & 0.31\% & 1.66\% \\
    $\Lambda_{n_{50}}$ & 4.37\% & 12.64\% & 2.27\% & 6.48\% & 0.12\% & 0.80\% \\
    $\Lambda_{n_{75}}$ & 3.20\% & 10.44\% & 1.72\% & 5.42\% & 0.08\% & 0.55\% \\
    $\Lambda_{n_{100}}$ & 2.55\% & 9.09\% & 1.39\% & 4.76\% & 0.07\% & 0.45\% \\
    $\Lambda_{D_{f1}}$ & 12.73\% & 34.28\% & 3.84\% & 14.11\% & 0.58\% & 5.46\% \\
    $\Lambda_{D_{f2}}$ & 10.15\% & 31.22\% & 3.71\% & 14.12\% & 0.51\% & 4.92\% \\
    $\Lambda_{D_{f3}}$ & 8.19\% & 28.48\% & 3.48\% & 13.98\% & 0.44\% & 4.47\% \\
    $\Lambda_{D_{f4}}$ & 6.67\% & 25.96\% & 3.17\% & 13.72\% & 0.38\% & 4.13\% \\
    $\Lambda_{D_{f5}}$ & 5.50\% & 23.46\% & 2.82\% & 13.15\% & 0.36\% & 4.08\% \\
    $\Lambda_{D_{f6}}$& 4.60\% & 21.31\% & 2.50\% & 12.57\% & 0.34\% & 3.93\% \\
    $\Lambda_{D_{f7}}$ & 3.90\% & 19.70\% & 2.23\% & 12.36\% & 0.31\% & 3.48\% \\
    $\Lambda_{c_{v1}}$ & 4.44\% & 20.67\% & 0.16\% & 0.50\% & 0.07\% & 0.43\% \\
    $\Lambda_{c_{v2}}$ & 5.22\% & 22.81\% & 0.93\% & 2.64\% & 0.06\% & 0.37\% \\
    $\Lambda_{c_{v3}}$ & 6.46\% & 25.73\% & 2.18\% & 5.57\% & 0.10\% & 0.45\% \\
    $\Lambda_{c_{v4}}$ & 7.92\% & 28.98\% & 3.63\% & 8.81\% & 0.33\% & 1.57\% \\
    $\Lambda_{c_{v5}}$ & 9.43\% & 32.19\% & 5.15\% & 12.02\% & 0.71\% & 3.12\% \\
    $\Lambda_{c_{v6}}$ & 10.87\% & 34.28\% & 6.59\% & 14.12\% & 1.23\% & 5.46\% \\
    \bottomrule
    \end{tabular}%
  \label{tab:summaryevatestbed}%
\end{table}%



\subsection{Numerical comparison of different optimization methods}

\subsubsection{Test bed}
 %Table generated by Excel2LaTeX from sheet 'Sheet30'
 In this subsection, we will conduct an other full factorial test bed to check how the optimal solution changed under different parameter settings. In consistency with the evaluation test bed, five factors are under investigation: the downtime budget factor $D_{f}$, the acquisition cost ${c}^{a}_{ij}$ ($i\in \rvert I \lvert$, $j \in \rvert J_{i} \lvert$), the expected failure rate $\mu_{ij}$ ($i\in \rvert I \lvert$, $j \in \rvert J_{i} \lvert$), the coefficient variation $c_{v}$ and the penalty rate $c_{p}$. The settings of these five factors can be found in Table \ref{tab:oppparametersetting}. Each factor has three levels, so 243 instances are generated by all combinations of the factor levels. Given that we have already prove that two-moment fit method is very accurate in evaluating a certain policy, the optimal solution of each instances are got by full enumeration combined with two-moment fit evaluation.
 \begin{table}[htbp]
 \footnotesize
  \centering
  \caption{Parameter setting for the optimization test bed}
 \begin{tabular}{*{3}{l}}
  \toprule
     Name of parameter & No. & Values\\
                      &val. &         \\
  \midrule
  Downtime budget factor ($D_{f}$) & 3     & 1, 1.1, 1.2 \\
  Acquisition cost and factor (${c}^{a}$, ${c}^{a}_{f}$) & 3 & $\left\{\begin{tabular}{@{\ }l@{}} 1) $\left\{\begin{tabular}{@{\ }l@{}}
    \hspace{11mm}$[500,\dots, 500i,\dots, 5000]$ \\ 1.5 $\times$ $[500,\dots, 500i,\dots, 5000]$
  \end{tabular}\right.$ \\
   2) $\left\{\begin{tabular}{@{\ }l@{}}
    \hspace{7mm} $[500,\dots, 500i,\dots, 5000]$ \\ 2 $\times$ $[500,\dots, 500i,\dots, 5000]$
  \end{tabular}\right.$ \\
     3) $\left\{\begin{tabular}{@{\ }l@{}}
   \hspace{10mm} $[500,\dots, 500i,\dots, 5000]$ \\ 2.5 $\times$ $[500,\dots, 500i,\dots, 5000]$
  \end{tabular}\right.$
  \end{tabular}\right.$\\
  Expected failure rates and factor  ($\mu$, $\mu_{f}$) & 3 & $\left\{\begin{tabular}{@{\ }l@{}} 1) $\left\{\begin{tabular}{@{\ }l@{}}
  $[0.1, 0.14, 0.12, 0.08, 0.06, 0.16, 0.18, 0.2, 0.04, 0.02]$\\
  $[0.1, 0.12, 0.11, 0.08, 0.03, 0.13, 0.14, 0.15, 0.03,	0.01]$
 \end{tabular}\right.$ \\
  2) $\left\{\begin{tabular}{@{\ }l@{}}
  $[0.1, 0.14, 0.12, 0.08, 0.06, 0.16, 0.18, 0.2, 0.04, 0.02]$\\
  $0.75 \times [0.1, 0.12, 0.11, 0.08, 0.03, 0.13, 0.14, 0.15, 0.03, 0.01]$
 \end{tabular}\right.$ \\
  3) $\left\{\begin{tabular}{@{\ }l@{}}
  $[0.1, 0.14, 0.12, 0.08, 0.06, 0.16, 0.18, 0.2, 0.04, 0.02]$\\
  $0.5 \times [0.1, 0.12, 0.11, 0.08, 0.03, 0.13, 0.14, 0.15, 0.03,	0.01]$
 \end{tabular}\right.$
 \end{tabular}\right.$\\
 Coefficient of variation ($c_{v}$) & 3 & 0.3, 0.9, 1.5 \\
 Penalty cost factor ($c^{p}$) & 3 & 1000, 5000, 10000\\
   \bottomrule
    \label{tab:oppparametersetting}
\end{tabular}
 \end{table}

The repair cost per repair $c^r_{ij}$ ($i \in \rvert I \lvert$, $j \in \rvert J_{i} \lvert$) are considered as a fix parameter, which equals to $30\%$ of the related $c^a_{ij}$. For each instance, we assume that the life cycle length $T$ is ten years, there are ten components in the system $(\rvert I \lvert = 10)$, and each component has two alternative designs to chose $(\rvert J_{i} \lvert=2)$.
 %The values for each fix parameters are shown in Table \ref{tab:oppfixpara}.
%\begin{table}[htbp]
%  \small
%  \centering
%  \caption{Values of fixed parameters}
%    \begin{tabular}{rrrrr}
%    \toprule
%    $T$ (year) & $r$ (h per repair) & $c_{r}$ (€ per repair) & \(\lvert $I$ \rvert\)   & \(\lvert $J$\rvert\) \\
%    \midrule
%    10    & 3     & 0.3$c_{ij}^{a}$ & 10    & 2 \\
%    \bottomrule
%    \end{tabular}%
%  \label{tab:oppfixpara}%
%\end{table}%



\subsubsection{Results and managerial insights}
To track the structural changes of the optimal solution under different parameter settings, we compare $\pi(\boldsymbol{x})$, $A(\boldsymbol{x})$, $R(\boldsymbol{x})$ and $P(\boldsymbol{x})$ of each instance with a standard case $(D_{f2}, c^{a}_{f2}, \mu_{f2}, c_{p2},c_{v2})$ which chose the medium level for each factor. We divide $(\pi(\boldsymbol{x}), A(\boldsymbol{x}), R(\boldsymbol{x}), P(\boldsymbol{x}))$ of each instance with $(\pi^{*}(\boldsymbol{x}), A^{*}(\boldsymbol{x}), R^{*}(\boldsymbol{x}), P^{*}(\boldsymbol{x}))$, which is the optimal solution of the standard case. The results of all instances are shown in Appendices \ref{appendix:oppdetailresults}. In Table \ref{tab:oppsummary} we categorize the instances in Table \ref{tab:oppdetailresults1}, Table \ref{tab:oppdetailresults2} and Table \ref{tab:oppdetailresults3} containing a specific level of a factor into a subset.
%\begin{table}[htbp]
%  \centering
%  \caption{Avg and Max gap of the optimization test bed}
%    \begin{tabular}{rrr}
%    \toprule
%          & avg gap & max gap \\
%    \midrule
%    $D_{f1}$ & 0.18\% & 4.55\% \\
%    $D_{f2}$ & 0.10\% & 4.51\% \\
%    $D_{f3}$ & 0.17\% & 3.37\% \\
%    $\boldsymbol{c}_{a1}$ & 0.12\% & 3.37\% \\
%    $\boldsymbol{c}_{a2}$ & 0.11\% & 3.82\% \\
%    $\boldsymbol{c}_{a3}$ & 0.23\% & 4.55\% \\
%    $\boldsymbol{\mu}_{1}$ & 0.24\% & 4.55\% \\
%    $\boldsymbol{\mu}_{2}$ & 0.15\% & 2.73\% \\
%    $\boldsymbol{\mu}_{3}$ & 0.07\% & 1.64\% \\
%    $c_{p1}$ & 0.07\% & 1.41\% \\
%    $c_{p2}$ & 0.19\% & 4.55\% \\
%    $c_{p3}$ & 0.20\% & 4.51\% \\
%    $c_{v1}$ & 0.06\% & 1.64\% \\
%    $c_{v2}$ & 0.03\% & 1.14\% \\
%    $c_{v3}$ & 0.37\% & 4.55\% \\
%    All instances & 0.15\% & 4.55\% \\
%    \bottomrule
%    \end{tabular}%
%  \label{tab:addlabel}%
%\end{table}%

% Table generated by Excel2LaTeX from sheet 'Sheet37'
% Table generated by Excel2LaTeX from sheet 'Sheet37'
\begin{table}[htbp]
\small
  \centering
  \caption{Summary of the test bed}
    \begin{tabular}{r|rrr|rrr|rrr|rrr}
    \hline
          & \multicolumn{3}{|c|}{$\pi$} & \multicolumn{3}{c|}{$c^{a}$} & \multicolumn{3}{c|}{$c^{r}$} & \multicolumn{3}{c}{$c^{p}$} \\
          & avg   & max   & min   & avg   & max   & min   & avg   & max   & min   & avg   & max   & min \\
 \hline
    $D_{f1}$ & 101\% & 191\% & 67\%  & 89\%  & 133\% & 67\%  & 88\%  & 132\% & 55\%  & 162\% & 586\% & 15\% \\
    $D_{f2}$ & 94\%  & 175\% & 66\%  & 86\%  & 126\% & 67\%  & 87\%  & 132\% & 55\%  & 133\% & 487\% & 10\% \\
    $D_{f3}$ & 89\%  & 158\% & 64\%  & 84\%  & 124\% & 67\%  & 86\%  & 121\% & 55\%  & 112\% & 494\% & 13\% \\
    \hline
    $c^{a}_{f1}$ & 85\%  & 160\% & 64\%  & 82\%  & 89\%  & 67\%  & 77\%  & 98\%  & 55\%  & 105\% & 519\% & 10\% \\
    $c^{a}_{f2}$ & 96\%  & 177\% & 64\%  & 87\%  & 111\% & 67\%  & 90\%  & 121\% & 70\%  & 136\% & 536\% & 29\% \\
    $c^{a}_{f3}$ & 103\% & 191\% & 64\%  & 89\%  & 133\% & 67\%  & 95\%  & 132\% & 86\%  & 166\% & 586\% & 29\% \\
    \hline
    $\mu_{f1}$ & 103\% & 191\% & 64\%  & 77\%  & 107\% & 67\%  & 95\%  & 132\% & 87\%  & 217\% & 586\% & 29\% \\
    $\mu_{f2}$ & 96\%  & 159\% & 66\%  & 89\%  & 126\% & 67\%  & 93\%  & 121\% & 77\%  & 127\% & 332\% & 34\% \\
    $\mu_{f3}$ & 85\%  & 126\% & 65\%  & 93\%  & 133\% & 69\%  & 74\%  & 88\%  & 55\%  & 62\%  & 137\% & 10\% \\
    \hline
    $c_{p1}$ & 70\%  & 78\%  & 64\%  & 70\%  & 84\%  & 67\%  & 84\%  & 87\%  & 59\%  & 59\%  & 101\% & 10\% \\
    $c_{p2}$ & 97\%  & 129\% & 69\%  & 89\%  & 116\% & 67\%  & 85\%  & 121\% & 55\%  & 142\% & 403\% & 18\% \\
    $c_{p3}$ & 117\% & 191\% & 71\%  & 100\% & 133\% & 71\%  & 92\%  & 132\% & 55\%  & 206\% & 586\% & 13\% \\
    \hline
    $c_{v1}$ & 87\%  & 147\% & 64\%  & 84\%  & 126\% & 67\%  & 86\%  & 121\% & 55\%  & 98\%  & 389\% & 13\% \\
    $c_{v2}$ & 94\%  & 168\% & 66\%  & 86\%  & 126\% & 67\%  & 87\%  & 121\% & 55\%  & 132\% & 517\% & 10\% \\
    $c_{v3}$ & 103\% & 191\% & 68\%  & 89\%  & 133\% & 67\%  & 88\%  & 132\% & 55\%  & 176\% & 586\% & 13\% \\
    \hline
     $\Lambda$& 95\%  & 191\% & 64\%  & 86\%  & 133\% & 67\%  & 87\%  & 132\% & 55\%  & 135\% & 586\% & 10\% \\
    \hline
    \end{tabular}%
  \label{tab:oppsummary}%
\end{table}%

% Table generated by Excel2LaTeX from sheet 'Sheet42'
\begin{table}[htbp]
  \centering
  \caption{Add caption}
    \begin{tabular}{rrrr}
    \toprule
          & \multicolumn{3}{c}{Percentage of expensive design choosen} \\
    \midrule
          & avg   & max   & min \\
    $D_{f1}$ & 44\%  & 80\%  & 0\% \\
    $D_{f2}$ & 41\%  & 80\%  & 0\% \\
    $D_{f3}$ & 37\%  & 80\%  & 0\% \\
    $c^{a}_{f1}$ & 55\%  & 80\%  & 0\% \\
    $c^{a}_{f2}$ & 38\%  & 80\%  & 0\% \\
    $c^{a}_{f3}$ & 30\%  & 80\%  & 0\% \\
    $\mu_{f1}$ & 21\%  & 60\%  & 0\% \\
    $\mu_{f2}$ & 45\%  & 80\%  & 0\% \\
    $\mu_{f3}$ & 56\%  & 80\%  & 10\% \\
    $c_{p1}$ & 13\%  & 60\%  & 0\% \\
    $c_{p2}$ & 46\%  & 80\%  & 0\% \\
    $c_{p3}$ & 62\%  & 80\%  & 10\% \\
    $c_{v1}$ & 37\%  & 80\%  & 0\% \\
    $c_{v2}$ & 41\%  & 80\%  & 0\% \\
    $c_{v3}$ & 44\%  & 80\%  & 0\% \\
    $\Lambda$ & 41\%  & 80\%  & 0\% \\
    \bottomrule
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%


As is shown in Table \ref{tab:oppsummary}, with $D_{f}$ increasing, $\pi(\boldsymbol{x})$ is decreasing because $D^{E}(\boldsymbol{x})$ is decreasing. And $\pi(\boldsymbol{x})$ increase when cost parameters $c^{a}_{f}$ and $c_{p}$ are higher. While the distribution parameters $\mu_{f}$ and $c_{v}$ also affect $\pi(\boldsymbol{x})$ in the same way, given that larger $\mu_{f}$ leads to larger number of failures and larger $c_{v}$ causes larger deviation of $D(\boldsymbol{x})$.

\section{Conclusion}
\newpage
\begin{appendices}


\section{Procedures of the Monte Carlo simulation}
\label{MCP}
\begin{description}
\item[Step 1]
First, we generated the sequences of $r_{i}$, $\mu_{i}$ and $\sigma_{i}$, $i=\{1,2,...,n\}$. Then we get $D_0$ immediately from Eq. \eqref{D0}. Furthermore, we take one sample $\hat{\Lambda}_{i}$ from $\Lambda_{i} \sim G(\mu_{i},\sigma_{i})$ for each component to simulate its failure rate $\lambda_{i}$, where $G(\mu_{i},\sigma_{i})$ is a general distribution with parameter mean $\mu_{i}$ and standard deviation $\sigma_{i}$. Given that the number of failures of each component $s_{i}$ is Poisson distributed with parameter $\lambda_{i}T$, we take one sample $\hat{S}_{i}$ from $S_{i}\sim$Pois$(\hat{\Lambda}_{i}T)$. Together with $r_{i}$, we get one simulation result $\hat{D}_{S}^{E}/D_{0}$ of the proportion of the exceeded total downtime $D_{E}/D_0$ computed as following:
\begin{eqnarray}
\hat{D}_{S}^{E}/D_{0}=\frac{\sum_{i=1}^{n}{\hat{S}_{i}r_{i}}-D_0}{\sum_{i=1}^{n}{\hat{S}_{i}r_{i}}}
\end{eqnarray}

\item[Step 2]

Repeat step 1 for 10000 times to get 10000 $\hat{D}_{S}^{E}/D_{0}$, we take the expected value $\bar{D}_{S}^{E}/D_{0}$ of all the $\hat{D}_{S}^{E}/D_{0}$ and compare it with the approximation result $D_{A1}^{E}/D_{0}$, $D_{A2}^{E}/D_{0}$ and $D_{A3}^{E}/D_{0}$ according to Eqs. \eqref{EXD1} or \eqref{EXD2}  to get values of the absolute gap between $\bar{D}_{S}^{E}/D_{0}$ and $D_{A1}^{E}/D_{0}$, $D_{A2}^{E}/D_{0}$ and $D_{A3}^{E}/D_{0}$.

\item[Step 3]

Repeat step 3 for 50 times to generate final simulation results of $D^{E}/D_{0}$, $D^{E}_{S}/D_{0}$. And the mean and maximum value for each gap and the confidence interval for $D^{E_{p}}_{S}$. The 95\% percent confidence interval is given as:
$$(D_{S}^{E}/D_{0}-t_{(49,2.5\%)}\sqrt{\frac{S^{2}(50)}{50}},\hspace{3mm}D_{S}^{E}/D_{0}+t_{(49,2.5\%)}\sqrt{\frac{S^{2}(50)}{50}} ) $$

\end{description}

\section{Derivations for the two-moment fits method}
\label{AG}

\subsection{Identities for the Erlang$(k-1,k)$ distribution}
\label{appendix:erlongk-1}
Consider an Erlang$(k-1,k)$ distribution $X$ with parameters $(k,\theta,q)$, the probability density function of is
\begin{eqnarray}
e_{k-1,k}(x)=q\theta^{k-1}\frac{x^{k-2}}{(k-2)!}e^{-\theta x} + (1-q)\theta^{k}\frac{x^{k-1}}{(k-1)!}e^{-\theta x} \nonumber
\end{eqnarray}
the cumulative distribution function of $X$ is
\begin{eqnarray}
E_{k-1,k}(x)=q\bigg(1-\sum_{j=0}^{k-2}\frac{(\theta x)^{j}}{j!}e^{-\theta x} \bigg)+(1-q)\bigg(1-\sum_{j=0}^{k-1}\frac{(\theta x)^{j}}{j!}e^{-\theta x} \bigg) \nonumber
\end{eqnarray}
Then the first partial moment of the Erlang$(k-1,k)$ can be described as:
\begin{eqnarray}
\mathbb{E}{[(X-X_{0})^{+}]} &=& \int_{0}^{\infty}{(x-X_{0})^{+}e_{k-1,k}(x)d x} \nonumber\\
&=& \frac{q(k-1)}{\theta}\int_{X_{0}}^{\infty}{\theta^{k}\frac{x^{k-1}}{(k-1)!}e^{-\theta x}dx}+\frac{k(1-q)}{\theta}\int_{X_0}^{\infty}{\theta^{k+1}\frac{x^{k}}{k!}e^{-\theta x}dx}\nonumber\\
&&-X_{0}\int_{X_{0}}^{\infty}{e_{k-1,k}(x)dx}\nonumber
\end{eqnarray}
Given the probability density function of an Erlang distribution is: $e_{k}^{\theta}(x)=\theta^{k}\frac{x^{k-1}}{(k-1)!}e^{-\theta x}$ and the Erlang cumulative distribution function is $E_{k}^{\theta}(X) = 1-\sum_{j=0}^{k-1}{\frac{(\lambda x)^{j}}{j!}e^{-\lambda x}}$, we have:
\begin{eqnarray}
\mathbb{E}{[(X-X_{0})^{+}]}
&=& \frac{q(k-1)}{\theta}\bigg[1-E_{k}^{\theta}(X_{0})\bigg]+\frac{k(1-q)}{\theta}\bigg[1-E_{k+1}^{\theta}(X_{0})\bigg]-X_{0}\bigg[1-E_{k-1,k}^{\theta}(X_{0})\bigg] \nonumber\\
&=&(\frac{k-q}{\theta}-X_{0})\sum_{j=0}^{k-2}{\frac{(\theta X_{0})^j}{j!}e^{-\theta X_{0}}}+(\frac{k-q}{\theta})\frac{(\theta X_{0})^{k-1}}{(k-1)!}e^{-\theta X_{0}}\nonumber
\end{eqnarray}


\subsection{Identities for the Hyperexponential distribution}
\label{appendix:hyperexponential}
For a Hyperexponential distribution $X$ with parameters $(\theta_1,\theta_2,q)$, the probability density function is given as:
\begin{eqnarray}
h_{2}(x) = q\theta_{1}e^{-\theta_{1}x} + (1-q)\theta_{2}e^{-\theta_{2}x} \nonumber
\end{eqnarray}
the cumulative distribution function is given as:
\begin{eqnarray}
H_{2}(x) = q(1-e^{-\theta_{1}x})+(1-q)(1-e^{-\theta_{2}x}) \nonumber
\end{eqnarray}
And the first partial moment is given as:
\begin{eqnarray}
\mathbb{E}{[(X-X_{0})^{+}]} &=& \int^{\infty}_{0}(x-X_{0})^{+}h_{2}(x)dx \nonumber\\
&=& \int^{\infty}_{X_{0}}{xq\theta_{1}e^{-\theta_{1}x}dx} + \int^{\infty}_{X_{0}}{x(1-q)\theta_{2}e^{-\theta_{2}x}dx}-X_{0}\int_{X_{0}}^{\infty}{h_{2}(x)dx} \nonumber\\
&=& qX_{0}e^{-\theta_{1}X_{0}} + \frac{q}{\theta_{1}}\int_{X_{0}}^{\infty}{\theta e^{-\theta_{1} x}dx} + (1-q)X_{0}e^{-\theta_{2}X_{0}} + \frac{1-q}{\theta_{2}}\int_{X_{0}}^{\infty}{\theta_{2}e^{-\theta_{2}x}dx} \nonumber\\
&& -X_{0}\bigg[1-H_{2}(X_{0}) \bigg] \nonumber
\end{eqnarray}
With the exponential probability density function $f_{\theta}(x)=\theta e^{-\theta x}$, and the exponential cumulative distribution function $F_{\theta}(x)= 1-e^{-\theta x}$, define the complementary distribution function of $F_{\theta}(x)$ as $\bar{F}_{\theta}(x)$, then the first partial moment can be written as:
\begin{eqnarray}
\mathbb{E}{[(X-X_{0})^{+}]}&=& qX_{0}e^{-\theta_{1}X_{0}} + (1-q)X_{0}e^{-\theta_{2}X_{0}} + \frac{q}{\theta_{1}}\bigg[1-F_{\theta_{1}}(X_{0})\bigg]+\frac{1-q}{\theta_{2}}\bigg[1-F_{\theta_{2}}(X_{0}) \bigg] \nonumber\\
&&-X_{0}\bigg[ 1- H_{2}(X_{0})\bigg] \nonumber
\end{eqnarray}


\section{Figures of the total downtime of the test bed}

\begin{figure}
\centering
\includegraphics[width=1.1\linewidth]{lognormal.eps}
 \caption{The simulation curve and approximation curve of the downtime density distribution under lognormal distributed failure rate}
 \label{fig:lognormal}
\end{figure}


\begin{figure}
\centering
\includegraphics[width=1.1\linewidth]{uniform.eps}
 \caption{The simulation curve and approximation curve of the downtime density distribution under uniform distributed failure rate}
  \label{fig:uniform}
\end{figure}


\section{Detail results of the computational results}
\label{appendix:oppdetailresults}
%
%\begin{table}[htbp]
%\small
%  \centering
%  \caption{Simulation and approximation results in the case of lognormal distributed failure rates}
%    \begin{tabular}{lllll}
%    \toprule
%   & & Confidence interval & & \\
%          & $D_{S1}^{E}/D_0$ & of $D_{S1}^{E}/D_0$  & $D^{E}_{A1}/D_{0}$, $D^{E}_{A2}/D_{0}$, $D^{E}_{A3}/D_{0}$ & $(avg$ $G_{A1}$, $avg$ $G_{A2}$, $avg$ $G_{A3})$ \\
%    \midrule
%    $(n_{1},\sigma_{1},D_{1})$  & 14.70\% & (14.68\%, 14.72\%) & (0\%, 14.14\%, 14.58\%) & (14.7\%, 0.56\%, 0.12\%) \\
%    $(n_{1},\sigma_{1},D_{2})$ & 9.59\% & (9.57\%, 9.6\%) & (0\%, 9.05\%, 9.62\%) & (9.59\%, 0.54\%, 0.03\%) \\
%    $(n_{1},\sigma_{1},D_{3})$ & 6.11\% & (6.1\%, 6.13\%) & (0\%, 5.69\%, 6.26\%) & (6.11\%, 0.42\%, 0.15\%) \\
%    $(n_{1},\sigma_{1},D_{4})$ & 3.84\% & (3.83\%, 3.85\%) & (0\%, 3.49\%, 4.02\%) & (3.84\%, 0.35\%, 0.18\%) \\
%   $(n_{1},\sigma_{2},D_{1})$ & 15.73\% & (15.7\%, 15.75\%) & (0\%, 14.14\%, 15.65\%) & (15.73\%, 1.59\%, 0.08\%) \\
%    $(n_{1},\sigma_{2},D_{2})$ & 10.55\% & (10.53\%, 10.56\%) & (0\%, 9.05\%, 10.58\%) & (10.55\%, 1.5\%, 0.03\%) \\
%   $(n_{1},\sigma_{2},D_{3})$ & 6.97\% & (6.95\%, 6.98\%) & (0\%, 5.69\%, 7.09\%) & (6.97\%, 1.28\%, 0.12\%) \\
%    $(n_{1},\sigma_{2},D_{4})$ & 4.55\% & (4.53\%, 4.56\%) & (0\%, 3.49\%, 4.71\%) & (4.55\%, 1.06\%, 0.16\%) \\
%     $(n_{1},\sigma_{3},D_{1})$  & 17.15\% & (17.13\%, 17.17\%) & (0\%, 14.14\%, 17.15\%) & (17.15\%, 3.01\%, 0\%) \\
%     $(n_{1},\sigma_{3},D_{2})$ & 11.89\% & (11.87\%, 11.91\%) & (0\%, 9.05\%, 11.96\%) & (11.89\%, 2.84\%, 0.07\%) \\
%     $(n_{1},\sigma_{3},D_{3})$ & 8.18\% & (8.16\%, 8.2\%) & (0\%, 5.69\%, 8.29\%) & (8.18\%, 2.49\%, 0.11\%) \\
%     $(n_{1},\sigma_{3},D_{4})$ & 5.60\% & (5.58\%, 5.61\%) & (0\%, 3.49\%, 5.72\%) & (5.6\%, 2.11\%, 0.12\%) \\
%   $(n_{2},\sigma_{1},D_{1})$ & 4.29\% & (4.28\%, 4.29\%) & (0\%, 3.98\%, 4.28\%) & (4.29\%, 0.31\%, 0.01\%) \\
%   $(n_{2},\sigma_{1},D_{2})$ & 0.98\% & (0.98\%, 0.98\%) & (0\%, 0.8\%, 1\%) & (0.98\%, 0.18\%, 0.02\%) \\
% $(n_{2},\sigma_{1},D_{3})$ & 0.14\% & (0.14\%, 0.14\%) & (0\%, 0.09\%, 0.15\%) & (0.14\%, 0.05\%, 0.01\%) \\
%    $(n_{2},\sigma_{1},D_{4})$ & 0.01\% & (0.01\%, 0.01\%) & (0\%, 0\%, 0.02\%) & (0.01\%, 0.01\%, 0.01\%) \\
%    $(n_{2},\sigma_{2},D_{1})$ & 4.82\% & (4.81\%, 4.83\%) & (0\%, 3.98\%, 4.82\%) & (4.82\%, 0.84\%, 0\%) \\
%    $(n_{2},\sigma_{2},D_{2})$ & 1.34\% & (1.34\%, 1.35\%) & (0\%, 0.8\%, 1.36\%) & (1.34\%, 0.54\%, 0.02\%) \\
%     $(n_{2},\sigma_{2},D_{3})$ & 0.27\% & (0.27\%, 0.27\%) & (0\%, 0.09\%, 0.28\%) & (0.27\%, 0.18\%, 0.01\%) \\
%     $(n_{2},\sigma_{2},D_{4})$ & 0.04\% & (0.04\%, 0.04\%) & (0\%, 0\%, 0.04\%) & (0.04\%, 0.04\%, 0\%) \\
%      $(n_{2},\sigma_{3},D_{1})$ & 5.54\% & (5.53\%, 5.55\%) & (0\%, 3.98\%, 5.56\%) & (5.54\%, 1.56\%, 0.02\%) \\
%     $(n_{2},\sigma_{3},D_{2})$ & 1.89\% & (1.89\%, 1.9\%) & (0\%, 0.8\%, 1.88\%) & (1.89\%, 1.09\%, 0.01\%) \\
%     $(n_{2},\sigma_{3},D_{3})$ & 0.52\% & (0.52\%, 0.52\%) & (0\%, 0.09\%, 0.51\%) & (0.52\%, 0.43\%, 0.01\%) \\
%      $(n_{2},\sigma_{3},D_{4})$ & 0.12\% & (0.12\%, 0.12\%) & (0\%, 0\%, 0.11\%) & (0.12\%, 0.12\%, 0.01\%) \\
%    $(n_{3},\sigma_{1},D_{1})$ & 3.05\% & (3.04\%, 3.05\%) & (0\%, 2.84\%, 3.05\%) & (3.05\%, 0.21\%, 0\%) \\
%    $(n_{3},\sigma_{1},D_{2})$ & 0.34\% & (0.33\%, 0.34\%) & (0\%, 0.25\%, 0.35\%) & (0.34\%, 0.09\%, 0.01\%) \\
%     $(n_{3},\sigma_{1},D_{3})$ & 0.01\% & (0.01\%, 0.01\%) & (0\%, 0.01\%, 0.02\%) & (0.01\%, 0\%, 0.01\%) \\
%    $(n_{3},\sigma_{1},D_{4})$ & 0.00\% & (0\%, 0\%) & (0\%, 0\%, 0\%) & (0\%, 0\%, 0\%) \\
%     $(n_{3},\sigma_{2},D_{1})$ & 3.44\% & (3.43\%, 3.44\%) & (0\%, 2.84\%, 3.44\%) & (3.44\%, 0.6\%, 0\%) \\
%    $(n_{3},\sigma_{2},D_{2})$  & 0.52\% & (0.52\%, 0.53\%) & (0\%, 0.25\%, 0.53\%) & (0.52\%, 0.27\%, 0.01\%) \\
%    $(n_{3},\sigma_{2},D_{3})$ & 0.04\% & (0.04\%, 0.04\%) & (0\%, 0.01\%, 0.04\%) & (0.04\%, 0.03\%, 0\%) \\
%     $(n_{3},\sigma_{2},D_{4})$ & 0.00\% & (0\%, 0\%) & (0\%, 0\%, 0\%) & (0\%, 0\%, 0\%) \\
%       $(n_{3},\sigma_{3},D_{1})$ & 3.96\% & (3.96\%, 3.97\%) & (0\%, 2.84\%, 3.97\%) & (3.96\%, 1.12\%, 0.01\%) \\
%       $(n_{3},\sigma_{3},D_{2})$ & 0.83\% & (0.82\%, 0.83\%) & (0\%, 0.25\%, 0.82\%) & (0.83\%, 0.58\%, 0.01\%) \\
%   $(n_{3},\sigma_{3},D_{3})$ & 0.11\% & (0.11\%, 0.11\%) & (0\%, 0.01\%, 0.1\%) & (0.11\%, 0.1\%, 0.01\%) \\
%     $(n_{3},\sigma_{3},D_{4})$ & 0.01\% & (0.01\%, 0.01\%) & (0\%, 0\%, 0.01\%) & (0.01\%, 0.01\%, 0\%) \\
%    \bottomrule
%    \end{tabular}%
%  \label{tab:lognormaldetail}%
%\end{table}%
% Table generated by Excel2LaTeX from sheet 'Sheet38'
\begin{table}[htbp]
\footnotesize
  \centering
  \caption{Results of the test bed (the percentage is the relative ratio dividing the optimal cost and cost elements by the standard case)}
    \begin{tabular}{llll}
    \toprule
    $\Lambda$ & ($\frac{\pi({\boldsymbol{x}})}{\pi^{*}({\boldsymbol{x}})}$,$\frac{A(\boldsymbol{x})}{A^{*}(\boldsymbol{x})}$,
    $\frac{R(\boldsymbol{x})}{R^{*}(\boldsymbol{x})}$, $\frac{P(\boldsymbol{x})}{P^{*}(\boldsymbol{x})}$ \%)    & $\Lambda$ & ($\frac{\pi({\boldsymbol{x}})}{\pi^{*}({\boldsymbol{x}})}$,$\frac{A(\boldsymbol{x})}{A^{*}(\boldsymbol{x})}$,
    $\frac{R(\boldsymbol{x})}{R^{*}(\boldsymbol{x})}$, $\frac{P(\boldsymbol{x})}{P^{*}(\boldsymbol{x})}$ \%) \\
    \midrule
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p1}$, $c_{v1}$) & (69, 67, 87, 57) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p2}$,$c_{v1}$) & (87, 84, 94, 94) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p1}$, $c_{v1}$) & (66, 67, 87, 41) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p2}$,$c_{v1}$) & (111, 93, 104, 194) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p1}$, $c_{v1}$) & (64, 67, 87, 29) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p2}$,$c_{v1}$) & (102, 78, 94, 203) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p1}$, $c_{v1}$) & (68, 67, 87, 57) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p2}$,$c_{v1}$) & (92, 73, 91, 173) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p1}$, $c_{v1}$) & (66, 67, 87, 41) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p2}$,$c_{v1}$) & (72, 89, 55, 23) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p1}$, $c_{v1}$) & (64, 67, 87, 29) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p2}$,$c_{v1}$) & (70, 86, 58, 21) \\
    ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p1}$, $c_{v1}$) & (69, 67, 87, 57) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p2}$,$c_{v1}$) & (69, 84, 59, 18) \\
    ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p1}$, $c_{v1}$) & (66, 67, 87, 41) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p2}$,$c_{v1}$) & (87, 100, 73, 49) \\
    ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p1}$, $c_{v1}$) & (64, 67, 87, 29) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p2}$, $c_{v1})$ & (84, 100, 73, 30) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p1}$, $c_{v1}$)& (71, 74, 83, 45) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p2}$, $c_{v1}$) & (81, 93, 75, 42) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p1}$, $c_{v1}$) & (68, 69, 87, 47) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p2}$,$c_{v1}$) & (100, 116, 86, 49) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p1}$, $c_{v1}$)& (66, 69, 87, 34) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p2}$,$c_{v1}$) & (95, 105, 86, 64) \\
     ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p1}$, $c_{v1}$) & (72, 67, 87, 79) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p2}$,$c_{v1}$) & (91, 93, 87, 88) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p1}$, $c_{v1}$) & (69, 67, 87, 61) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p3}$,$c_{v1}$) & (119, 86, 98, 270) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p1}$, $c_{v1}$) & (67, 67, 87, 47) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p3}$,$c_{v1}$) & (103, 86, 98, 176) \\
     ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p1}$, $c_{v1}$) & (72, 67, 87, 79) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p3}$,$c_{v1}$) & (91, 84, 96, 116) \\
     ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p1}$, $c_{v1}$) & (69, 67, 87, 61) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p3}$,$c_{v1}$) & (135, 101, 121, 285) \\
     ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p1}$, $c_{v1}$) & (67, 67, 87, 47) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p3}$,$c_{v1}$) & (118, 94, 112, 218) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p1}$,$c_{v1}$) & (67, 80, 65, 19) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p3}$,$c_{v1}$) & (103, 76, 90, 228) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu\_{f3}$, $c_{p1}$,$c_{v1}$) & (66, 80, 65, 13) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p3}$,$c_{v1}$) & (147, 95, 114, 389) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p1}$,$c_{v1}$) & (65, 78, 66, 13) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p3}$,$c_{v1}$) & (125, 80, 93, 336) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p1}$,$c_{v1}$) & (74, 71, 86, 73) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p3}$,$c_{v1}$) & (106, 71, 91, 262) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p1}$, $c_{v1}$) & (71, 71, 86, 58) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p3}$,$c_{v1}$) & (95, 89, 78, 133) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p1}$,$c_{v1}$) & (69, 71, 86, 45) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p3}$,$c_{v1}$) & (86, 89, 78, 82) \\
    ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p1}$,$c_{v1}$) & (75, 73, 87, 73) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p3}$,$c_{v1}$) & (80, 87, 77, 57) \\
    ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p1}$,$c_{v1}$) & (72, 73, 87, 58) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p3}$,$c_{v1}$) & (113, 106, 99, 153) \\
    ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p1}$,$c_{v1}$) & (70, 69, 87, 60) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p3}$,$c_{v1}$) & (103, 106, 99, 96) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p2}$,$c_{v1}$) & (96, 84, 96, 143) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p3}$,$c_{v1}$) & (96, 100, 100, 77) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p2}$,$c_{v1}$) & (87, 80, 93, 110) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p3}$,$c_{v1}$) & (129, 126, 120, 153) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p2}$,$c_{v1}$) & (80, 76, 90, 88) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p3}$,$c_{v1}$) & (118, 116, 121, 124) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p2}$,$c_{v1}$) & (105, 76, 90, 238) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p3}$,$c_{v1}$) & (109, 105, 113, 119) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p2}$,$c_{v1}$) & (93, 70, 90, 189) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p3}$,$c_{v1}$) & (76, 89, 55, 45) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p2}$,$c_{v1}$) & (83, 67, 87, 143) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p3}$,$c_{v1})$ & (73, 89, 55, 26) \\
    ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p2}$,$c_{v1}$) & (106, 67, 87, 284) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p3}$,$c_{v1}$) & (71, 89, 55, 13) \\
    ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p2}$,$c_{v1}$) & (93, 67, 87, 205) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p3}$,$c_{v1}$) & (93, 111, 70, 45) \\
    ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p2}$,$c_{v1}$) & (83, 67, 87, 144) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p3}$,$c_{v1}$) & (89, 100, 73, 60) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p2}$,$c_{v1}$) & (83, 87, 77, 76) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p3}$,$c_{v1}$) & (85, 100, 73, 35) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p2}$,$c_{v1}$) & (79, 87, 77, 48) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p3}$,$c_{v1}$) & (108, 116, 86, 98) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p2}$,$c_{v1}$) & (75, 84, 79, 39) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p3}$,$c_{v1}$) & (102, 116, 86, 60) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p2}$,$c_{v1}$) & (99, 100, 100, 96) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p3}$,$c_{v1}$) & (98, 116, 86, 35) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p2}$,$c_{v1}$) & (93, 93, 97, 92) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p1}$,$c_{v2}$) & (71, 67, 87, 70) \\
    \bottomrule
    \end{tabular}%
  \label{tab:oppdetailresults1}%
\end{table}%



\begin{table}[htbp]
\footnotesize
  \centering
  \caption{Results of the test bed (the percentage is the relative ratio dividing the optimal cost and cost elements by the standard case) continued}
    \begin{tabular}{llll}
    \toprule
        $\Lambda$ & ($\frac{\pi({\boldsymbol{x}})}{\pi^{*}({\boldsymbol{x}})}$,$\frac{A(\boldsymbol{x})}{A^{*}(\boldsymbol{x})}$,
    $\frac{R(\boldsymbol{x})}{R^{*}(\boldsymbol{x})}$, $\frac{P(\boldsymbol{x})}{P^{*}(\boldsymbol{x})}$ \%)    & $\Lambda$ & ($\frac{\pi({\boldsymbol{x}})}{\pi^{*}({\boldsymbol{x}})}$,$\frac{A(\boldsymbol{x})}{A^{*}(\boldsymbol{x})}$,
    $\frac{R(\boldsymbol{x})}{R^{*}(\boldsymbol{x})}$, $\frac{P(\boldsymbol{x})}{P^{*}(\boldsymbol{x})}$ \%) \\
   \midrule

    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p1}$,$c_{v2}$) & (68, 67, 87, 55) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p2}$,$c_{v2}$) & (120, 105, 113, 183) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p1}$,$c_{v2}$) & (66, 67, 87, 43) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p2}$,$c_{v2}$) & (111, 93, 104, 192) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p1}$,$c_{v2}$) & (71, 67, 87, 69) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p2}$,$c_{v2}$) & (103, 78, 94, 211) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p1}$,$c_{v2}$) & (68, 67, 87, 55) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p2}$,$c_{v2}$) & (75, 89, 55, 39) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p1}$,$c_{v2}$) & (66, 67, 87, 43) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p2}$,$c_{v2}$) & (73, 89, 55, 27) \\
    ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p1}$,$c_{v2}$) & (71, 67, 87, 69) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p2}$,$c_{v2}$) & (71, 86, 58, 25) \\
    ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p1}$,$c_{v2}$) & (68, 67, 87, 55) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p2}$,$c_{v2}$) & (91, 100, 73, 74) \\
    ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p1}$,$c_{v2}$) & (66, 67, 87, 43) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p2}$,$c_{v2}$) & (87, 100, 73, 51) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p1}$,$c_{v2}$) & (72, 74, 83, 56) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p2}$,$c_{v2}$) & (85, 100, 73, 35) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p1}$,$c_{v2}$) & (70, 69, 87, 60) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p2}$,$c_{v2}$) & (104, 116, 86, 73) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p1}$,$c_{v2}$) & (68, 69, 87, 48) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p2}$,$c_{v2}$) & (101, 116, 86, 51) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p1}$,$c_{v2}$) & (74, 67, 87, 89) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p2}$,$c_{v2}$) & (97, 105, 86, 74) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p1}$,$c_{v2}$) & (71, 67, 87, 73) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p3}$,$c_{v2}$) & (138, 86, 98, 384) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p1}$,$c_{v2}$) & (69, 67, 87, 60) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p3}$,$c_{v2}$) & (122, 86, 98, 288) \\
    ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p1}$,$c_{v2}$) & (74, 67, 87, 89) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p3}$,$c_{v2}$) & (109, 86, 98, 211) \\
    ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p1}$,$c_{v2}$) & (71, 67, 87, 74) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p3}$,$c_{v2}$) & (154, 101, 121, 398) \\
    ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p1}$,$c_{v2}$) & (69, 67, 87, 60) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p3}$,$c_{v2}$) & (137, 101, 121, 298) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p1}$,$c_{v2}$) & (68, 84, 59, 15) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p3}$,$c_{v2}$) & (123, 94, 112, 253) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p1}$,$c_{v2}$) & (67, 84, 59, 10) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p3}$,$c_{v2}$) & (168, 95, 114, 517) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p1}$,$c_{v2}$) & (67, 80, 65, 15) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p3}$,$c_{v2}$) & (147, 80, 93, 473) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p1}$,$c_{v2}$) & (75, 71, 86, 82) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p3}$,$c_{v2}$) & (129, 71, 91, 402) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p1}$,$c_{v2}$) & (73, 71, 86, 68) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p3}$,$c_{v2}$) & (107, 89, 78, 208) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p1}$,$c_{v2}$) & (71, 71, 86, 57) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p3}$,$c_{v2}$) & (97, 89, 78, 149) \\
    ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p1}$,$c_{v2}$) & (77, 73, 87, 82) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p3}$,$c_{v2}$) & (90, 89, 78, 106) \\
    ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p1}$,$c_{v2}$) & (74, 73, 87, 69) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p3}$,$c_{v2}$) & (125, 111, 101, 207) \\
    ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p1}$,$c_{v2}$) & (72, 69, 87, 72) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p3}$,$c_{v2}$) & (115, 106, 99, 166) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p2}$,$c_{v2}$) & (105, 84, 96, 199) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p3}$,$c_{v2}$) & (107, 106, 99, 119) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p2}$,$c_{v2}$) & (97, 84, 96, 150) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p3}$,$c_{v2}$) & (142, 126, 120, 231) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p2}$,$c_{v2}$) & (90, 80, 93, 127) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p3}$,$c_{v2}$) & (131, 116, 121, 199) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p2}$,$c_{v2}$) & (116, 76, 90, 303) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p3}$,$c_{v2}$) & (122, 116, 121, 144) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p2}$,$c_{v2}$) & (104, 70, 90, 259) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p3}$,$c_{v2}$) & (82, 89, 55, 78) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p2}$,$c_{v2}$) & (95, 70, 90, 202) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p3}$,$c_{v2}$) & (77, 89, 55, 53) \\
    ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p2}$,$c_{v2}$) & (117, 67, 87, 348) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p3}$,$c_{v2}$) & (74, 89, 55, 35) \\
    ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p2}$,$c_{v2}$) & (105, 67, 87, 276) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p3}$,$c_{v2}$) & (99, 111, 70, 79) \\
    ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p2}$,$c_{v2}$) & (95, 67, 87, 215) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p3}$,$c_{v2}$) & (95, 111, 70, 53) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p2}$,$c_{v2}$) & (90, 89, 78, 104) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p3}$,$c_{v2}$) & (91, 105, 73, 51) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p2}$,$c_{v2}$) & (85, 87, 77, 84) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p3}$,$c_{v2}$) & (116, 124, 88, 111) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p2}$,$c_{v2}$) & (81, 87, 77, 59) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p3}$,$c_{v2}$) & (109, 116, 86, 103) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p2}$,$c_{v2}$) & (106, 100, 100, 137) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p3}$,$c_{v2}$) & (104, 116, 86, 72) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p2}$,$c_{v2}$) & (100, 100, 100, 100) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p1}$,$c_{v3}$) & (73, 67, 87, 84) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p2}$,$c_{v2}$) & (95, 93, 97, 104) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p1}$,$c_{v3}$) & (71, 67, 87, 71) \\
    \bottomrule
    \end{tabular}%
  \label{tab:oppdetailresults2}%
\end{table}%

% Table generated by Excel2LaTeX from sheet 'Sheet38'
% Table generated by Excel2LaTeX from sheet 'Sheet38'
\begin{table}[htbp]
\footnotesize
  \centering
  \caption {Results of the test bed (the percentage is the relative ratio dividing the optimal cost and cost elements by the standard case) continued}
    \begin{tabular}{llll}
    \toprule
    $\Lambda$ & ($\frac{\pi({\boldsymbol{x}})}{\pi^{*}({\boldsymbol{x}})}$,$\frac{A(\boldsymbol{x})}{A^{*}(\boldsymbol{x})}$,
    $\frac{R(\boldsymbol{x})}{R^{*}(\boldsymbol{x})}$, $\frac{P(\boldsymbol{x})}{P^{*}(\boldsymbol{x})}$ \%)    & $\Lambda$ & ($\frac{\pi({\boldsymbol{x}})}{\pi^{*}({\boldsymbol{x}})}$,$\frac{A(\boldsymbol{x})}{A^{*}(\boldsymbol{x})}$,
    $\frac{R(\boldsymbol{x})}{R^{*}(\boldsymbol{x})}$, $\frac{P(\boldsymbol{x})}{P^{*}(\boldsymbol{x})}$ \%) \\
     \midrule
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p1}$,$c_{v3}$) & (69, 67, 87, 60) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p2}$,$c_{v3}$) & (129, 116, 121, 190) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p1}$,$c_{v3}$) & (73, 67, 87, 84) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p2}$,$c_{v3}$) & (122, 105, 113, 198) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p1}$,$c_{v3}$) & (71, 67, 87, 72) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p2}$,$c_{v3}$) & (115, 93, 104, 216) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p1}$,$c_{v3}$) & (69, 67, 87, 60) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p2}$,$c_{v3}$) & (80, 89, 55, 68) \\
    ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p1}$,$c_{v3}$) & (73, 67, 87, 84) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p2}$,$c_{v3}$) & (77, 89, 55, 52) \\
    ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p1}$,$c_{v3}$) & (71, 67, 87, 71) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p2}$,$c_{v3}$) & (75, 89, 55, 40) \\
    ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p1}$,$c_{v3}$) & (69, 67, 87, 60) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p2}$,$c_{v3}$) & (97, 105, 73, 87) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p1}$,$c_{v3}$) & (75, 78, 81, 54) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p2}$,$c_{v3}$) & (93, 100, 73, 86) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p1}$,$c_{v3}$) & (73, 74, 83, 57) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p2}$,$c_{v3}$) & (90, 100, 73, 67) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p1}$,$c_{v3}$) & (71, 74, 83, 48) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p2}$,$c_{v3}$) & (110, 116, 86, 109) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p1}$,$c_{v3}$) & (76, 67, 87, 101) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p2}$,$c_{v3}$) & (106, 116, 86, 86) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p1}$,$c_{v3}$) & (74, 67, 87, 88) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p2}$,$c_{v3}$) & (103, 116, 86, 68) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p1}$,$c_{v3}$) & (72, 67, 87, 76) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p3}$,$c_{v3}$) & (160, 86, 98, 519) \\
    ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p1}$,$c_{v3}$) & (76, 67, 87, 101) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p3}$,$c_{v3}$) & (145, 86, 98, 427) \\
    ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p1}$,$c_{v3}$) & (74, 67, 87, 88) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p3}$,$c_{v3}$) & (132, 86, 98, 348) \\
    ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p1}$,$c_{v3}$) & (72, 67, 87, 76) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p3}$,$c_{v3}$) & (177, 101, 121, 536) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p1}$,$c_{v3}$) & (69, 84, 59, 22) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p3}$,$c_{v3}$) & (161, 101, 121, 440) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p1}$,$c_{v3}$) & (68, 84, 59, 17) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p3}$,$c_{v3}$) & (148, 101, 121, 361) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p1}$,$c_{v3}$) & (68, 84, 59, 13) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p3}$,$c_{v3}$) & (191, 107, 132, 586) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p1}$,$c_{v3}$) & (77, 71, 86, 93) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p3}$,$c_{v3}$) & (175, 107, 132, 487) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p1}$,$c_{v3}$) & (75, 71, 86, 81) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p3}$,$c_{v3}$) & (158, 85, 113, 494) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p1}$,$c_{v3}$) & (73, 71, 86, 70) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p3}$,$c_{v3}$) & (123, 89, 78, 306) \\
    ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p1}$,$c_{v3}$) & (78, 73, 87, 93) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p3}$,$c_{v3}$) & (113, 89, 78, 245) \\
    ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p1}$,$c_{v3}$) & (76, 73, 87, 81) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p3}$,$c_{v3}$) & (105, 89, 78, 197) \\
    ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p1}$,$c_{v3}$) & (75, 73, 87, 71) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p3}$,$c_{v3}$) & (142, 111, 101, 308) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p2}$,$c_{v3}$) & (117, 84, 96, 268) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p3}$,$c_{v3}$) & (132, 111, 101, 246) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p2}$,$c_{v3}$) & (109, 84, 96, 220) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p3}$,$c_{v3}$) & (123, 106, 99, 214) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f1}$, $c_{p2}$,$c_{v3}$) & (102, 84, 96, 181) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p3}$,$c_{v3}$) & (159, 126, 120, 332) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p2}$,$c_{v3}$) & (128, 79, 102, 352) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p3}$,$c_{v3}$) & (148, 126, 120, 267) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p2}$,$c_{v3}$) & (117, 70, 90, 338) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f2}$, $c_{p3}$,$c_{v3}$) & (139, 116, 121, 246) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f1}$, $c_{p2}$,$c_{v3}$) & (109, 70, 90, 286) & ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p3}$,$c_{v3}$) & (91, 89, 55, 136) \\
    ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p2}$,$c_{v3}$) & (129, 71, 91, 403) & ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p3}$,$c_{v3}$) & (86, 89, 55, 105) \\
    ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p2}$,$c_{v3}$) & (118, 67, 87, 356) & ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f3}$, $c_{p3}$,$c_{v3}$) & (82, 89, 55, 80) \\
    ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f1}$, $c_{p2}$,$c_{v3}$) & (109, 67, 87, 302) & ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p3}$,$c_{v3}$) & (109, 111, 70, 137) \\
    ($D_{f1}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p2}$,$c_{v3}$) & (98, 89, 78, 154) & ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p3}$,$c_{v3}$) & (103, 111, 70, 104) \\
    ($D_{f2}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p2}$,$c_{v3}$) & (93, 89, 78, 122) & ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f3}$, $c_{p3}$,$c_{v3}$) & (99, 111, 70, 80) \\
    ($D_{f3}$, $c^{a}_{f1}$, $\mu_{f2}$, $c_{p2}$,$c_{v3}$) & (89, 87, 77, 107) & ($D_{f1}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p3}$,$c_{v3}$) & (126, 133, 86, 136) \\
    ($D_{f1}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p2}$,$c_{v3}$) & (115, 100, 100, 190) & ($D_{f2}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p3}$,$c_{v3}$) & (120, 124, 88, 135) \\
    ($D_{f2}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p2}$,$c_{v3}$) & (109, 100, 100, 153) & ($D_{f3}$, $c^{a}_{f3}$, $\mu_{f3}$, $c_{p3}$,$c_{v3}$) & (115, 124, 88, 105) \\
    ($D_{f3}$, $c^{a}_{f2}$, $\mu_{f2}$, $c_{p2}$,$c_{v3}$) & (104, 100, 100, 124) &       &  \\
    \bottomrule
    \end{tabular}%
  \label{tab:oppdetailresults3}%
\end{table}%

\end{appendices}

\newpage
\section{References}
%\bibliographystyle{model2-names}
\bibliographystyle{plainnat}
\bibliography{reference}


\end{document}  